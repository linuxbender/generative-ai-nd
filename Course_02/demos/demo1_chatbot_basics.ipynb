{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 1: Building a Basic Chatbot with LLMs\n",
    "\n",
    "In this demo, you'll learn how to interact with OpenAI's API to build a simple chatbot. We'll explore:\n",
    "\n",
    "1. **Basic API calls** - Making your first request\n",
    "2. **Conversation context** - Maintaining chat history\n",
    "3. **System prompts** - Controlling bot behavior\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this demo, you'll understand:\n",
    "- How to make basic API calls to LLMs\n",
    "- How to build a stateful conversation\n",
    "- How system prompts shape bot behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the required libraries and set up our API key."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T19:32:26.312877Z",
     "start_time": "2025-12-24T19:32:26.273597Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set your API key (get from environment or replace with your key)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "base_url = os.getenv(\"OPENAI_BASE_URL\")  # Optional: for custom endpoints\n",
    "\n",
    "print(api_key)\n",
    "\n",
    "# Initialize the client\n",
    "# For Vocareum keys, use: base_url=\"https://openai.vocareum.com/v1\"\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "print(\"‚úÖ OpenAI client initialized!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voc-10694876731266774594167694c2af1d65632.81978761\n",
      "‚úÖ OpenAI client initialized!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Basic API Call\n",
    "\n",
    "Let's start with a simple question and see how the LLM responds."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T19:32:28.998083Z",
     "start_time": "2025-12-24T19:32:26.313898Z"
    }
   },
   "source": [
    "# Simple question\n",
    "question = \"What is an embedding?\"\n",
    "\n",
    "# Make the API call\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=100\n",
    ")\n",
    "\n",
    "# Extract the answer\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"\\nAnswer: {answer}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is an embedding?\n",
      "\n",
      "Answer: An embedding is a method used in natural language processing and machine learning to represent words or phrases as vectors in a continuous vector space. This allows words to be represented numerically, making it easier for machine learning algorithms to process and analyze textual data. Embeddings capture semantic and syntactic relationships between words, enabling algorithms to understand the context and meaning of words in a given text. Popular embedding techniques include Word2Vec, GloVe, and FastText.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§î What Just Happened?\n",
    "\n",
    "The LLM generated a response by **predicting the next most likely word** repeatedly. This simple mechanism enables complex, coherent responses!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Building a Stateful Conversation\n",
    "\n",
    "LLMs are **stateless** - they don't remember previous messages unless you include them! Let's build a proper conversation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T19:32:32.721581Z",
     "start_time": "2025-12-24T19:32:29.003719Z"
    }
   },
   "source": [
    "# Initialize conversation history\n",
    "conversation = []\n",
    "\n",
    "def chat(user_message):\n",
    "    \"\"\"Send a message and get a response, maintaining conversation history.\"\"\"\n",
    "    \n",
    "    # Add user message to history\n",
    "    conversation.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_message\n",
    "    })\n",
    "    \n",
    "    # Make API call with full conversation history\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=conversation,\n",
    "        temperature=0.7,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    \n",
    "    # Get assistant's response\n",
    "    assistant_message = response.choices[0].message.content\n",
    "    \n",
    "    # Add assistant's response to history\n",
    "    conversation.append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": assistant_message\n",
    "    })\n",
    "    \n",
    "    return assistant_message\n",
    "\n",
    "# Have a conversation!\n",
    "print(\"User: What's the weather like today?\")\n",
    "response1 = chat(\"What's the weather like today?\")\n",
    "print(f\"Bot: {response1}\\n\")\n",
    "\n",
    "print(\"User: Should I bring an umbrella?\")\n",
    "response2 = chat(\"Should I bring an umbrella?\")  # References previous context!\n",
    "print(f\"Bot: {response2}\\n\")\n",
    "\n",
    "print(\"User: Thanks! What about tomorrow?\")\n",
    "response3 = chat(\"Thanks! What about tomorrow?\")  # Still maintaining context\n",
    "print(f\"Bot: {response3}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What's the weather like today?\n",
      "Bot: I'm sorry, I am an AI assistant and do not have real-time information. Please check a weather website or app for the current weather in your location.\n",
      "\n",
      "User: Should I bring an umbrella?\n",
      "Bot: It is always a good idea to bring an umbrella with you just in case, especially if there is a chance of rain in the forecast. It's better to be prepared!\n",
      "\n",
      "User: Thanks! What about tomorrow?\n",
      "Bot: I apologize for the inconvenience, but as an AI assistant, I do not have the ability to provide real-time weather updates or forecasts. I recommend checking a reliable weather website or app for the most up-to-date information on tomorrow's weather in your location.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù View Conversation History\n",
    "\n",
    "Let's see what we're sending to the API with each request:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T19:32:32.731181Z",
     "start_time": "2025-12-24T19:32:32.726854Z"
    }
   },
   "source": [
    "print(\"Current conversation history:\\n\")\n",
    "print(json.dumps(conversation, indent=2))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current conversation history:\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"What's the weather like today?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"I'm sorry, I am an AI assistant and do not have real-time information. Please check a weather website or app for the current weather in your location.\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"Should I bring an umbrella?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"It is always a good idea to bring an umbrella with you just in case, especially if there is a chance of rain in the forecast. It's better to be prepared!\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"Thanks! What about tomorrow?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"I apologize for the inconvenience, but as an AI assistant, I do not have the ability to provide real-time weather updates or forecasts. I recommend checking a reliable weather website or app for the most up-to-date information on tomorrow's weather in your location.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: System Prompts - Controlling Behavior\n",
    "\n",
    "System prompts are **secret instructions** that define how the bot should behave. The user never sees them, but they dramatically affect responses!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T19:32:37.590886Z",
     "start_time": "2025-12-24T19:32:32.731656Z"
    }
   },
   "source": [
    "def create_bot_with_personality(system_prompt):\n",
    "    \"\"\"Create a bot with a specific personality.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me about troubleshooting.\"}\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Test different personalities\n",
    "print(\"ü§ñ Professional Bot:\")\n",
    "professional = create_bot_with_personality(\n",
    "    \"You are a professional tech support assistant. Be formal and concise.\"\n",
    ")\n",
    "print(professional)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"üòä Friendly Bot:\")\n",
    "friendly = create_bot_with_personality(\n",
    "    \"You are a friendly, enthusiastic tech support assistant. Use casual language and be upbeat!\"\n",
    ")\n",
    "print(friendly)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"üé≠ Pirate Bot (just for fun!):\")\n",
    "pirate = create_bot_with_personality(\n",
    "    \"You are a pirate tech support assistant. Respond in pirate speak with 'arr' and 'matey'!\"\n",
    ")\n",
    "print(pirate)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Professional Bot:\n",
      "Troubleshooting is the process of identifying, diagnosing, and resolving problems within a system or device. It involves systematically investigating the issue to determine its root cause and implementing a solution to fix the problem. Troubleshooting often requires analytical thinking, knowledge of the system or device, and the ability to follow a logical step-by-step approach to resolve technical issues effectively.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üòä Friendly Bot:\n",
      "Hey there! Troubleshooting is basically trying to figure out why something isn't working the way it should and then fixing it. It's like being a detective for tech problems! Whether it's a glitchy app, a slow computer, or a wonky internet connection, troubleshooting helps you get things back on track. Just stay calm, take it step by step, and you'll usually find a solution! Got any tech issues you need help with?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üé≠ Pirate Bot (just for fun!):\n",
      "Arr, troubleshooting be the art of findin' and fixin' problems with yer devices, matey. It be like huntin' for buried treasure, but instead of gold, ye be seekin' out the source of technical woes. Ye must be patient and thorough in yer quest, for the solution to the problem may be hidden like a secret map. If ye be havin' a glitch or issue with yer device, fear not! I be here to help ye navigate the treacher\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Building a Tech Support Bot\n",
    "\n",
    "Now let's put it all together to build a simple tech support chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T19:32:44.307163Z",
     "start_time": "2025-12-24T19:32:37.595962Z"
    }
   },
   "source": [
    "# Initialize a tech support bot\n",
    "tech_support_bot = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are a helpful tech support assistant for TechCo, a software company.\n",
    "        \n",
    "Your responsibilities:\n",
    "- Troubleshoot software issues and bugs\n",
    "- Help with installation and setup problems\n",
    "- Explain error messages\n",
    "- Guide users through configuration steps\n",
    "\n",
    "Guidelines:\n",
    "- Be patient and clear in your explanations\n",
    "- Ask diagnostic questions to identify the problem\n",
    "- Provide step-by-step solutions\n",
    "- If the issue requires developer attention, offer to create a support ticket\n",
    "\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "def tech_support_chat(user_message):\n",
    "    \"\"\"Tech support chat function.\"\"\"\n",
    "    tech_support_bot.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=tech_support_bot,\n",
    "        temperature=0.7,\n",
    "        max_tokens=200\n",
    "    )\n",
    "    \n",
    "    assistant_message = response.choices[0].message.content\n",
    "    tech_support_bot.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "    \n",
    "    return assistant_message\n",
    "\n",
    "# Simulate tech support interactions\n",
    "test_messages = [\n",
    "    \"My application keeps crashing when I try to export a file.\",\n",
    "    \"I'm using version 2.5 on Windows 11.\",\n",
    "    \"I tried that but it's still not working. What else can I do?\"\n",
    "]\n",
    "\n",
    "for msg in test_messages:\n",
    "    print(f\"üë§ User: {msg}\")\n",
    "    response = tech_support_chat(msg)\n",
    "    print(f\"ü§ñ Bot: {response}\\n\")\n",
    "    print(\"=\"*80 + \"\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ User: My application keeps crashing when I try to export a file.\n",
      "ü§ñ Bot: I'm sorry to hear that you're experiencing issues with exporting files in the application. Let's troubleshoot this together. \n",
      "\n",
      "First, could you provide more details about the crash? Do you receive any error messages when the application crashes? \n",
      "\n",
      "Also, have you tried exporting different types of files, or is it happening with a specific file format? \n",
      "\n",
      "Lastly, please let me know which operating system you're using so we can tailor the solution to your setup.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üë§ User: I'm using version 2.5 on Windows 11.\n",
      "ü§ñ Bot: Thank you for providing that information. Since you're using the application on Windows 11, let's try a few troubleshooting steps to address the crashing issue when exporting files:\n",
      "\n",
      "1. **Check for Updates**: Make sure you are using the latest version of the application. Sometimes, updates include bug fixes that can resolve crashing issues.\n",
      "\n",
      "2. **Check File Size**: If you are trying to export a very large file, it could be causing the application to crash. Try exporting a smaller file to see if the issue persists.\n",
      "\n",
      "3. **Check File Format**: Certain file formats might be causing the crash. Try exporting the file in a different format to see if that resolves the issue.\n",
      "\n",
      "4. **Run as Administrator**: Right-click on the application's shortcut and select \"Run as Administrator.\" Sometimes, this can help with permissions issues that might be causing the crash.\n",
      "\n",
      "5. **Check System Requirements**: Ensure that your system meets the minimum requirements for running the application. Insufficient system resources can sometimes cause crashes\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üë§ User: I tried that but it's still not working. What else can I do?\n",
      "ü§ñ Bot: I'm sorry to hear that the previous steps didn't resolve the issue. Let's try a few more troubleshooting steps:\n",
      "\n",
      "1. **Check Event Viewer**: You can check the Event Viewer in Windows to see if there are any specific error messages related to the application crash. Look for any critical or error events around the time the application crashes.\n",
      "\n",
      "2. **Reinstall the Application**: Uninstall the application completely and then reinstall it. Sometimes, a fresh installation can resolve crashing issues caused by corrupted files.\n",
      "\n",
      "3. **Check for Conflicting Software**: Some third-party software or security programs can conflict with the application and cause it to crash. Try temporarily disabling any antivirus or security software and see if the issue persists.\n",
      "\n",
      "4. **Create a New User Account**: Create a new user account on your Windows system and try running the application from that account. This can help determine if the issue is related to your user profile.\n",
      "\n",
      "If none of these steps resolve the issue, it's possible that there may be a\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Key Takeaways\n",
    "\n",
    "1. **LLMs predict the next word** - that's the fundamental operation, but it enables complex behaviors\n",
    "\n",
    "2. **Conversation requires state** - you must include message history in each API call\n",
    "\n",
    "3. **System prompts are powerful** - they shape behavior without the user seeing them\n",
    "\n",
    "4. **Structure matters** - messages have roles (system, user, assistant) that guide the model\n",
    "\n",
    "## üí∞ Cost Considerations\n",
    "\n",
    "Each API call costs money based on tokens:\n",
    "- System prompt: counted every time\n",
    "- Conversation history: grows with each turn\n",
    "- New message: adds more tokens\n",
    "- Response: output tokens cost more!\n",
    "\n",
    "**Pro tip**: Long conversations get expensive. Consider truncating old history in production.\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "Try these experiments:\n",
    "1. Change the temperature (0 = deterministic, 1+ = creative)\n",
    "2. Modify the system prompt to create different personalities\n",
    "3. Add intent classification before generating responses\n",
    "4. Implement conversation summarization for long chats\n",
    "\n",
    "Move on to **Demo 2: Tokenization** to learn about cost optimization!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0 (main, Dec  3 2024, 02:26:48) [GCC 12.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "23393d2575091a37cff0d0e9e7479591a295495b26c3b2ebf9b64da572e02d85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
