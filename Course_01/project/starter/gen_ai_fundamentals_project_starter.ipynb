{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ws1RZXWHfBM"
      },
      "source": [
        "# Project: Teaching an LLM to Reason\n",
        "\n",
        "In this project, you will teach an LLM to use step-by-step reasoning to answer the question: \"How many X's are there in the word Y?\"\n",
        "\n",
        "Counting letters in a word is a surprisingly complex task for an LLM. Just as human beings would not be able to answer such a question for longer words without breaking down the word into its individual letters and then counting them, LLMs cannot be similarly expected to be able to respond without using smaller reasoning steps.\n",
        "\n",
        "For example, to count the number of o's in the word room, one could use the following reasoning:\n",
        "\n",
        "```\n",
        "Question: How many of the letter \"o\" are there in the word \"room\"\n",
        "Answer: 2\n",
        "Response:\n",
        "\n",
        "<reasoning>\n",
        "Letter-by-letter spelling:\n",
        "1. r - 0 o's so far\n",
        "2. o - 1 o's so far\n",
        "3. o - 2 o's so far\n",
        "4. m - 2 o's so far\n",
        "\n",
        "The letter \"o\" appears 2 times in the word \"room\".\n",
        "</reasoning>\n",
        "<answer>\n",
        "2\n",
        "</answer>\n",
        "```\n",
        "\n",
        "In this project we will use the reinforcement learning method GRPO (Group Relative Policy Optimization, of DeepSeek fame) to take a large language model that has been fine-tuned for following instructions and teach it how to break a word down into its letters and then count the requested letter.\n",
        "\n",
        "We will complete the following steps:\n",
        "\n",
        "* Set up the notebook\n",
        "* Create a letter-counting dataset\n",
        "* Create the reward functions\n",
        "* Train the model\n",
        "* View the results\n",
        "\n",
        "NOTE: This notebook will have you focus on several important aspects of training a GPRO model using LoRA:\n",
        "\n",
        "1. Configuring LoRA adapters for parameter-efficient fine tuning\n",
        "2. Selecting reward functions that help the model efficiently find its way to the correct answer (also called reward shaping)\n",
        "3. Finding hyperparameters that help the model increase the rewards earned more quickly and reliably\n",
        "4. Learning how to start with smaller experiments and to work your way up to longer experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzGNMBhkHfBO"
      },
      "source": [
        "## Set up the notebook\n",
        "\n",
        "We'll install dependencies needed for the project, namely `unsloth` and `vllm`, which are useful for fine-tuning LLMs with even just 15GB of VRAM."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unsloth==2025.9.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hR2EMssJRsF4",
        "outputId": "08b6ae9e-ef40-4bd3-df64-d9d34c8d48ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth==2025.9.7\n",
            "  Downloading unsloth-2025.9.7-py3-none-any.whl.metadata (54 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unsloth_zoo>=2025.9.9 (from unsloth==2025.9.7)\n",
            "  Downloading unsloth_zoo-2025.12.6-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth==2025.9.7) (2.9.0+cu126)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth==2025.9.7)\n",
            "  Downloading xformers-0.0.33.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting bitsandbytes (from unsloth==2025.9.7)\n",
            "  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth==2025.9.7) (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth==2025.9.7) (25.0)\n",
            "Collecting tyro (from unsloth==2025.9.7)\n",
            "  Downloading tyro-1.0.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3 (from unsloth==2025.9.7)\n",
            "  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets<4.0.0,>=3.4.1 (from unsloth==2025.9.7)\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth==2025.9.7) (0.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth==2025.9.7) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth==2025.9.7) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth==2025.9.7) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth==2025.9.7) (2.0.2)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth==2025.9.7) (1.12.0)\n",
            "Collecting trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth==2025.9.7)\n",
            "  Downloading trl-0.26.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth==2025.9.7) (0.18.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth==2025.9.7) (5.29.5)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth==2025.9.7) (0.36.0)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth==2025.9.7) (0.1.9)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth==2025.9.7) (0.36.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth==2025.9.7) (0.24.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth==2025.9.7) (6.0.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth==2025.9.7) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth==2025.9.7) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth==2025.9.7) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2025.9.7) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2025.9.7) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2025.9.7) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2025.9.7) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2025.9.7) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2025.9.7) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2025.9.7) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2025.9.7) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2025.9.7) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2025.9.7) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2025.9.7) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2025.9.7) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2025.9.7) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2025.9.7) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2025.9.7) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2025.9.7) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2025.9.7) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2025.9.7) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth==2025.9.7) (1.11.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3->unsloth==2025.9.7) (2025.11.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3->unsloth==2025.9.7)\n",
            "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "INFO: pip is looking at multiple versions of trl to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth==2025.9.7)\n",
            "  Downloading trl-0.26.1-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading trl-0.26.0-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading trl-0.25.1-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading trl-0.25.0-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading trl-0.24.0-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading trl-0.23.1-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading trl-0.23.0-py3-none-any.whl.metadata (11 kB)\n",
            "INFO: pip is still looking at multiple versions of trl to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading trl-0.22.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting torchao>=0.13.0 (from unsloth_zoo>=2025.9.9->unsloth==2025.9.7)\n",
            "  Downloading torchao-0.15.0-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.9.9->unsloth==2025.9.7)\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.9.9->unsloth==2025.9.7) (11.3.0)\n",
            "Collecting msgspec (from unsloth_zoo>=2025.9.9->unsloth==2025.9.7)\n",
            "  Using cached msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting torch>=2.4.0 (from unsloth==2025.9.7)\n",
            "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.4.0->unsloth==2025.9.7)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.4.0->unsloth==2025.9.7)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.4.0->unsloth==2025.9.7)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.10.2.21->torch>=2.4.0->unsloth==2025.9.7)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.4.0->unsloth==2025.9.7)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.4.0->unsloth==2025.9.7)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.4.0->unsloth==2025.9.7)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.7.1.2->torch>=2.4.0->unsloth==2025.9.7)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.4.0->unsloth==2025.9.7)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cufft-cu12==11.3.0.4->torch>=2.4.0->unsloth==2025.9.7)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.4.0->unsloth==2025.9.7)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton>=3.0.0 (from unsloth==2025.9.7)\n",
            "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth==2025.9.7) (8.7.0)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth==2025.9.7) (0.28.1)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from unsloth==2025.9.7)\n",
            "  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth==2025.9.7) (0.17.0)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth==2025.9.7) (4.4.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->diffusers->unsloth==2025.9.7) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->diffusers->unsloth==2025.9.7) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->diffusers->unsloth==2025.9.7) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->diffusers->unsloth==2025.9.7) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->diffusers->unsloth==2025.9.7) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (2.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth==2025.9.7) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth==2025.9.7) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth==2025.9.7) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0,>=3.4.1->unsloth==2025.9.7) (1.17.0)\n",
            "Downloading unsloth-2025.9.7-py3-none-any.whl (314 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.6/314.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m126.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.22.2-py3-none-any.whl (544 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m544.8/544.8 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.12.6-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.6/289.6 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.33.post2-cp39-abi3-manylinux_2_28_x86_64.whl (122.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/122.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m132.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (8.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m132.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-1.0.3-py3-none-any.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m122.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchao-0.15.0-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m127.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchao, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, tyro, nvidia-cusparse-cu12, nvidia-cufft-cu12, tokenizers, nvidia-cusolver-cu12, transformers, torch, datasets, xformers, torchvision, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo, unsloth\n",
            "  Attempting uninstall: torchao\n",
            "    Found existing installation: torchao 0.10.0\n",
            "    Uninstalling torchao-0.10.0:\n",
            "      Successfully uninstalled torchao-0.10.0\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.3\n",
            "    Uninstalling transformers-4.57.3:\n",
            "      Successfully uninstalled transformers-4.57.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cu126\n",
            "    Uninstalling torch-2.9.0+cu126:\n",
            "      Successfully uninstalled torch-2.9.0+cu126\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.24.0+cu126\n",
            "    Uninstalling torchvision-0.24.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.24.0+cu126\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.49.0 cut_cross_entropy-25.1.1 datasets-3.6.0 msgspec-0.20.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 tokenizers-0.21.4 torch-2.9.1 torchao-0.15.0 torchvision-0.24.1 transformers-4.55.4 triton-3.5.1 trl-0.22.2 tyro-1.0.3 unsloth-2025.9.7 unsloth_zoo-2025.12.6 xformers-0.0.33.post2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vllm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "JvUomyvtUEox",
        "outputId": "6ca11db7-0686-41ae-b8b9-c047e5a5b3ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vllm\n",
            "  Using cached vllm-0.13.0-cp38-abi3-manylinux_2_31_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from vllm) (2025.11.3)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from vllm) (6.2.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from vllm) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from vllm) (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from vllm) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from vllm) (4.67.1)\n",
            "Collecting blake3 (from vllm)\n",
            "  Using cached blake3-1.0.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from vllm) (9.0.0)\n",
            "Collecting transformers<5,>=4.56.0 (from vllm)\n",
            "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.21.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from vllm) (5.29.5)\n",
            "Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.123.10)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from vllm) (3.13.2)\n",
            "Requirement already satisfied: openai>=1.99.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.12.0)\n",
            "Requirement already satisfied: pydantic>=2.12.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.12.3)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.23.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from vllm) (11.3.0)\n",
            "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
            "  Using cached prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.12.0)\n",
            "Collecting lm-format-enforcer==0.11.3 (from vllm)\n",
            "  Using cached lm_format_enforcer-0.11.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting llguidance<1.4.0,>=1.3.0 (from vllm)\n",
            "  Using cached llguidance-1.3.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting outlines_core==0.2.11 (from vllm)\n",
            "  Using cached outlines_core-0.2.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting diskcache==5.6.3 (from vllm)\n",
            "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting lark==1.2.2 (from vllm)\n",
            "  Using cached lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xgrammar==0.1.27 (from vllm)\n",
            "  Using cached xgrammar-0.1.27-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.15.0)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (3.20.0)\n",
            "Collecting partial-json-parser (from vllm)\n",
            "  Using cached partial_json_parser-0.2.1.1.post7-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (26.2.1)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.12/dist-packages (from vllm) (0.20.0)\n",
            "Collecting gguf>=0.17.0 (from vllm)\n",
            "  Using cached gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting mistral_common>=1.8.5 (from mistral_common[image]>=1.8.5->vllm)\n",
            "  Using cached mistral_common-1.8.8-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.12.0.88)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from vllm) (6.0.3)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.17.0)\n",
            "Collecting setuptools<81.0.0,>=77.0.3 (from vllm)\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from vllm) (0.8.1)\n",
            "Collecting compressed-tensors==0.12.2 (from vllm)\n",
            "  Using cached compressed_tensors-0.12.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting depyf==0.20.0 (from vllm)\n",
            "  Using cached depyf-0.20.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from vllm) (3.1.2)\n",
            "Collecting watchfiles (from vllm)\n",
            "  Using cached watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.12/dist-packages (from vllm) (4.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from vllm) (1.16.3)\n",
            "Collecting ninja (from vllm)\n",
            "  Using cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting pybase64 (from vllm)\n",
            "  Using cached pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Collecting cbor2 (from vllm)\n",
            "  Using cached cbor2-5.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting ijson (from vllm)\n",
            "  Using cached ijson-3.4.0.post0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
            "Collecting setproctitle (from vllm)\n",
            "  Using cached setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (10 kB)\n",
            "Collecting openai-harmony>=0.0.3 (from vllm)\n",
            "  Using cached openai_harmony-0.0.8-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Collecting anthropic==0.71.0 (from vllm)\n",
            "  Downloading anthropic-0.71.0-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting model-hosting-container-standards<1.0.0,>=0.1.9 (from vllm)\n",
            "  Downloading model_hosting_container_standards-0.1.12-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: mcp in /usr/local/lib/python3.12/dist-packages (from vllm) (1.24.0)\n",
            "Collecting numba==0.61.2 (from vllm)\n",
            "  Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting ray>=2.48.0 (from ray[cgraph]>=2.48.0->vllm)\n",
            "  Downloading ray-2.53.0-cp312-cp312-manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting torch==2.9.0 (from vllm)\n",
            "  Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: torchaudio==2.9.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.9.0+cu126)\n",
            "Collecting torchvision==0.24.0 (from vllm)\n",
            "  Downloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "Collecting flashinfer-python==0.5.3 (from vllm)\n",
            "  Downloading flashinfer_python-0.5.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (1.3.1)\n",
            "Collecting loguru (from compressed-tensors==0.12.2->vllm)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting astor (from depyf==0.20.0->vllm)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from depyf==0.20.0->vllm) (0.3.8)\n",
            "Collecting apache-tvm-ffi<0.2,>=0.1 (from flashinfer-python==0.5.3->vllm)\n",
            "  Downloading apache_tvm_ffi-0.1.6-cp312-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.3->vllm) (8.3.1)\n",
            "Collecting nvidia-cudnn-frontend>=1.13.0 (from flashinfer-python==0.5.3->vllm)\n",
            "  Downloading nvidia_cudnn_frontend-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting nvidia-cutlass-dsl>=4.2.1 (from flashinfer-python==0.5.3->vllm)\n",
            "  Downloading nvidia_cutlass_dsl-4.3.4-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.3->vllm) (13.590.44)\n",
            "Requirement already satisfied: packaging>=24.2 in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.3->vllm) (25.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.3->vllm) (0.9.0)\n",
            "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.11.3->vllm)\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm)\n",
            "  Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (1.13.1.3)\n",
            "Collecting triton==3.5.0 (from torch==2.9.0->vllm)\n",
            "  Downloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.50.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.0.4)\n",
            "Collecting fastapi-cli>=0.0.8 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi_cli-0.0.20-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\n",
            "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.38.0)\n",
            "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (4.25.1)\n",
            "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm)\n",
            "  Downloading pydantic_extra_types-2.10.6-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting jmespath (from model-hosting-container-standards<1.0.0,>=0.1.9->vllm)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting supervisor>=4.2.0 (from model-hosting-container-standards<1.0.0,>=0.1.9->vllm)\n",
            "  Downloading supervisor-4.3.0-py2.py3-none-any.whl.metadata (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.0->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.0->vllm) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.0->vllm) (0.4.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm) (1.1.2)\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.12/dist-packages (from ray[cgraph]>=2.48.0->vllm) (13.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (2025.11.12)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.21.1->vllm) (0.36.0)\n",
            "Collecting tokenizers>=0.21.1 (from vllm)\n",
            "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.56.0->vllm) (0.7.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.22.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp->vllm) (0.4.3)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp->vllm) (2.12.0)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp->vllm) (2.10.1)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp->vllm) (3.0.4)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.20.0)\n",
            "Collecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading rich_toolkit-0.17.1-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi_cloud_cli-0.7.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic==0.71.0->vllm) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic==0.71.0->vllm) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.21.1->vllm) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0->vllm) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (0.30.0)\n",
            "Requirement already satisfied: cuda-python>=12.8 in /usr/local/lib/python3.12/dist-packages (from nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.3->vllm) (12.9.4)\n",
            "Collecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp->vllm) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp->vllm) (43.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.0->vllm) (1.3.0)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x->ray[cgraph]>=2.48.0->vllm) (0.8.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp->vllm) (2.0.0)\n",
            "Requirement already satisfied: cuda-bindings~=12.9.4 in /usr/local/lib/python3.12/dist-packages (from cuda-python>=12.8->nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.3->vllm) (12.9.4)\n",
            "Collecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading rignore-0.7.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.47.0)\n",
            "Collecting fastar>=0.8.0 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastar-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (13.9.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp->vllm) (2.23)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings~=12.9.4->cuda-python>=12.8->nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.3->vllm) (1.3.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n",
            "Downloading vllm-0.13.0-cp38-abi3-manylinux_2_31_x86_64.whl (474.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.9/474.9 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anthropic-0.71.0-py3-none-any.whl (355 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.0/355.0 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading compressed_tensors-0.12.2-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.0/183.0 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading depyf-0.20.0-py3-none-any.whl (39 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flashinfer_python-0.5.3-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_format_enforcer-0.11.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines_core-0.2.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgrammar-0.1.27-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gguf-0.17.1-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llguidance-1.3.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistral_common-1.8.8-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m121.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading model_hosting_container_standards-0.1.12-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai_harmony-0.0.8-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
            "Downloading ray-2.53.0-cp312-cp312-manylinux2014_x86_64.whl (72.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m119.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blake3-1.0.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (388 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.0/388.0 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cbor2-5.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (285 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.7/285.7 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ijson-3.4.0.post0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.0/149.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading partial_json_parser-0.2.1.1.post7-py3-none-any.whl (10 kB)\n",
            "Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (32 kB)\n",
            "Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading apache_tvm_ffi-0.1.6-cp312-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
            "Downloading fastapi_cli-0.0.20-py3-none-any.whl (12 kB)\n",
            "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_frontend-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cutlass_dsl-4.3.4-cp312-cp312-manylinux_2_28_x86_64.whl (58.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_extra_types-2.10.6-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading supervisor-4.3.0-py2.py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi_cloud_cli-0.7.0-py3-none-any.whl (23 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich_toolkit-0.17.1-py3-none-any.whl (31 kB)\n",
            "Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastar-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (821 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.6/821.6 kB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rignore-0.7.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (959 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m959.8/959.8 kB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: supervisor, uvloop, triton, setuptools, setproctitle, rignore, pycountry, pybase64, partial-json-parser, outlines_core, nvidia-cudnn-frontend, ninja, loguru, llvmlite, llguidance, lark, jmespath, interegular, ijson, httptools, gguf, fastar, dnspython, diskcache, cbor2, blake3, astor, apache-tvm-ffi, watchfiles, numba, email-validator, depyf, torch, tokenizers, rich-toolkit, pydantic-extra-types, prometheus-fastapi-instrumentator, openai-harmony, nvidia-cutlass-dsl, lm-format-enforcer, anthropic, transformers, torchvision, ray, model-hosting-container-standards, flashinfer-python, fastapi-cloud-cli, fastapi-cli, xgrammar, mistral_common, compressed-tensors, vllm\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.1\n",
            "    Uninstalling triton-3.5.1:\n",
            "      Successfully uninstalled triton-3.5.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: lark\n",
            "    Found existing installation: lark 1.3.1\n",
            "    Uninstalling lark-1.3.1:\n",
            "      Successfully uninstalled lark-1.3.1\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.1\n",
            "    Uninstalling torch-2.9.1:\n",
            "      Successfully uninstalled torch-2.9.1\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.4\n",
            "    Uninstalling tokenizers-0.21.4:\n",
            "      Successfully uninstalled tokenizers-0.21.4\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.55.4\n",
            "    Uninstalling transformers-4.55.4:\n",
            "      Successfully uninstalled transformers-4.55.4\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.24.1\n",
            "    Uninstalling torchvision-0.24.1:\n",
            "      Successfully uninstalled torchvision-0.24.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "unsloth 2025.9.7 requires transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3, but you have transformers 4.57.3 which is incompatible.\n",
            "xformers 0.0.33.post2 requires torch==2.9.1, but you have torch 2.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed anthropic-0.71.0 apache-tvm-ffi-0.1.6 astor-0.8.1 blake3-1.0.8 cbor2-5.7.1 compressed-tensors-0.12.2 depyf-0.20.0 diskcache-5.6.3 dnspython-2.8.0 email-validator-2.3.0 fastapi-cli-0.0.20 fastapi-cloud-cli-0.7.0 fastar-0.8.0 flashinfer-python-0.5.3 gguf-0.17.1 httptools-0.7.1 ijson-3.4.0.post0 interegular-0.3.3 jmespath-1.0.1 lark-1.2.2 llguidance-1.3.0 llvmlite-0.44.0 lm-format-enforcer-0.11.3 loguru-0.7.3 mistral_common-1.8.8 model-hosting-container-standards-0.1.12 ninja-1.13.0 numba-0.61.2 nvidia-cudnn-frontend-1.17.0 nvidia-cutlass-dsl-4.3.4 openai-harmony-0.0.8 outlines_core-0.2.11 partial-json-parser-0.2.1.1.post7 prometheus-fastapi-instrumentator-7.1.0 pybase64-1.4.3 pycountry-24.6.1 pydantic-extra-types-2.10.6 ray-2.53.0 rich-toolkit-0.17.1 rignore-0.7.6 setproctitle-1.3.7 setuptools-80.9.0 supervisor-4.3.0 tokenizers-0.22.1 torch-2.9.0 torchvision-0.24.0 transformers-4.57.3 triton-3.5.0 uvloop-0.22.1 vllm-0.13.0 watchfiles-1.1.1 xgrammar-0.1.27\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "functorch",
                  "tokenizers",
                  "torch",
                  "torchgen",
                  "torchvision",
                  "transformers",
                  "triton"
                ]
              },
              "id": "919a8e39dc514050bdc6c941a3185fd1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2min 55s (started: 2025-12-22 18:27:07 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade unsloth unsloth_zoo vllm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "IxIc6ofEWnwG",
        "outputId": "9d3bf959-cf75-491c-a3cd-33fbd29d8e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unsloth in /usr/local/lib/python3.12/dist-packages (2025.9.7)\n",
            "Collecting unsloth\n",
            "  Using cached unsloth-2025.12.8-py3-none-any.whl.metadata (65 kB)\n",
            "Requirement already satisfied: unsloth_zoo in /usr/local/lib/python3.12/dist-packages (2025.12.6)\n",
            "Requirement already satisfied: vllm in /usr/local/lib/python3.12/dist-packages (0.13.0)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.45.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth) (25.0)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.9.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.24.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.9.5)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.12/dist-packages (from unsloth) (1.0.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.29.5)\n",
            "Requirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.0.33.post2)\n",
            "Requirement already satisfied: bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.49.0)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (3.5.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.2.1)\n",
            "Requirement already satisfied: datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (3.6.0)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (1.12.0)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.18.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.36.0)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.1.9)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.36.0)\n",
            "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.57.3)\n",
            "Requirement already satisfied: trl!=0.19.0,<=0.24.0,>=0.18.2 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.22.2)\n",
            "Requirement already satisfied: torchao>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo) (0.15.0)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo) (25.1.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo) (11.3.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo) (2025.11.3)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo) (0.20.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo) (3.20.0)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from vllm) (6.2.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.32.4)\n",
            "Requirement already satisfied: blake3 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.0.8)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from vllm) (9.0.0)\n",
            "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.22.1)\n",
            "Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.123.10)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from vllm) (3.13.2)\n",
            "Requirement already satisfied: openai>=1.99.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.12.0)\n",
            "Requirement already satisfied: pydantic>=2.12.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.12.3)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.23.1)\n",
            "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (7.1.0)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.12.0)\n",
            "Requirement already satisfied: lm-format-enforcer==0.11.3 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.11.3)\n",
            "Requirement already satisfied: llguidance<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.3.0)\n",
            "Requirement already satisfied: outlines_core==0.2.11 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.2.11)\n",
            "Requirement already satisfied: diskcache==5.6.3 in /usr/local/lib/python3.12/dist-packages (from vllm) (5.6.3)\n",
            "Requirement already satisfied: lark==1.2.2 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.2.2)\n",
            "Requirement already satisfied: xgrammar==0.1.27 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.1.27)\n",
            "Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.12/dist-packages (from vllm) (0.2.1.1.post7)\n",
            "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (26.2.1)\n",
            "Requirement already satisfied: gguf>=0.17.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.17.1)\n",
            "Requirement already satisfied: mistral_common>=1.8.5 in /usr/local/lib/python3.12/dist-packages (from mistral_common[image]>=1.8.5->vllm) (1.8.8)\n",
            "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.12.0.88)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from vllm) (6.0.3)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.17.0)\n",
            "Requirement already satisfied: setuptools<81.0.0,>=77.0.3 in /usr/local/lib/python3.12/dist-packages (from vllm) (80.9.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from vllm) (0.8.1)\n",
            "Requirement already satisfied: compressed-tensors==0.12.2 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.12.2)\n",
            "Requirement already satisfied: depyf==0.20.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.20.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from vllm) (3.1.2)\n",
            "Requirement already satisfied: watchfiles in /usr/local/lib/python3.12/dist-packages (from vllm) (1.1.1)\n",
            "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.12/dist-packages (from vllm) (4.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from vllm) (1.16.3)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from vllm) (1.13.0)\n",
            "Requirement already satisfied: pybase64 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.4.3)\n",
            "Requirement already satisfied: cbor2 in /usr/local/lib/python3.12/dist-packages (from vllm) (5.7.1)\n",
            "Requirement already satisfied: ijson in /usr/local/lib/python3.12/dist-packages (from vllm) (3.4.0.post0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.12/dist-packages (from vllm) (1.3.7)\n",
            "Requirement already satisfied: openai-harmony>=0.0.3 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.0.8)\n",
            "Requirement already satisfied: anthropic==0.71.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.71.0)\n",
            "Requirement already satisfied: model-hosting-container-standards<1.0.0,>=0.1.9 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.1.12)\n",
            "Requirement already satisfied: mcp in /usr/local/lib/python3.12/dist-packages (from vllm) (1.24.0)\n",
            "Requirement already satisfied: numba==0.61.2 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.61.2)\n",
            "Requirement already satisfied: ray>=2.48.0 in /usr/local/lib/python3.12/dist-packages (from ray[cgraph]>=2.48.0->vllm) (2.53.0)\n",
            "Requirement already satisfied: torchaudio==2.9.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.9.0+cu126)\n",
            "Requirement already satisfied: flashinfer-python==0.5.3 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.5.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (1.3.1)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.12/dist-packages (from compressed-tensors==0.12.2->vllm) (0.7.3)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.12/dist-packages (from depyf==0.20.0->vllm) (0.8.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from depyf==0.20.0->vllm) (0.3.8)\n",
            "Requirement already satisfied: apache-tvm-ffi<0.2,>=0.1 in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.3->vllm) (0.1.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.3->vllm) (8.3.1)\n",
            "Requirement already satisfied: nvidia-cudnn-frontend>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.3->vllm) (1.17.0)\n",
            "Requirement already satisfied: nvidia-cutlass-dsl>=4.2.1 in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.3->vllm) (4.3.4)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.3->vllm) (13.590.44)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.3->vllm) (0.9.0)\n",
            "Requirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from lm-format-enforcer==0.11.3->vllm) (0.3.3)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba==0.61.2->vllm) (0.44.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.13.1.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth) (0.7.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (18.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.70.16)\n",
            "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.50.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.0.4)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.8 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.0.20)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\n",
            "Requirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (2.3.0)\n",
            "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.38.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.0)\n",
            "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (4.25.1)\n",
            "Requirement already satisfied: pydantic-extra-types>=2.10.5 in /usr/local/lib/python3.12/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (2.10.6)\n",
            "Requirement already satisfied: jmespath in /usr/local/lib/python3.12/dist-packages (from model-hosting-container-standards<1.0.0,>=0.1.9->vllm) (1.0.1)\n",
            "Requirement already satisfied: supervisor>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from model-hosting-container-standards<1.0.0,>=0.1.9->vllm) (4.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.0->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.0->vllm) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.0->vllm) (0.4.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm) (1.1.2)\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.12/dist-packages (from ray[cgraph]>=2.48.0->vllm) (13.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (2025.11.12)\n",
            "INFO: pip is looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
            "  Downloading xformers-0.0.33.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.22.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth) (8.7.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp->vllm) (0.4.3)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp->vllm) (2.12.0)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp->vllm) (2.10.1)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp->vllm) (3.0.4)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (4.4.4)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm) (2.8.0)\n",
            "Requirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.20.0)\n",
            "Requirement already satisfied: rich-toolkit>=0.14.8 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.17.1)\n",
            "Requirement already satisfied: fastapi-cloud-cli>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.7.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic==0.71.0->vllm) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic==0.71.0->vllm) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (0.30.0)\n",
            "Requirement already satisfied: cuda-python>=12.8 in /usr/local/lib/python3.12/dist-packages (from nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.3->vllm) (12.9.4)\n",
            "Requirement already satisfied: pycountry>=23 in /usr/local/lib/python3.12/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (24.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp->vllm) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp->vllm) (43.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.7.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.22.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x->ray[cgraph]>=2.48.0->vllm) (0.8.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp->vllm) (2.0.0)\n",
            "Requirement already satisfied: cuda-bindings~=12.9.4 in /usr/local/lib/python3.12/dist-packages (from cuda-python>=12.8->nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.3->vllm) (12.9.4)\n",
            "Requirement already satisfied: rignore>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.7.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.47.0)\n",
            "Requirement already satisfied: fastar>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.8.0)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (13.9.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp->vllm) (2.23)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings~=12.9.4->cuda-python>=12.8->nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.3->vllm) (1.3.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n",
            "Downloading unsloth-2025.12.8-py3-none-any.whl (376 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.1/376.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.33.post1-cp39-abi3-manylinux_2_28_x86_64.whl (122.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/122.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xformers, unsloth\n",
            "  Attempting uninstall: xformers\n",
            "    Found existing installation: xformers 0.0.33.post2\n",
            "    Uninstalling xformers-0.0.33.post2:\n",
            "      Successfully uninstalled xformers-0.0.33.post2\n",
            "  Attempting uninstall: unsloth\n",
            "    Found existing installation: unsloth 2025.9.7\n",
            "    Uninstalling unsloth-2025.9.7:\n",
            "      Successfully uninstalled unsloth-2025.9.7\n",
            "Successfully installed unsloth-2025.12.8 xformers-0.0.33.post1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "unsloth",
                  "xformers"
                ]
              },
              "id": "b704b6bcbfab40df9078df3a2d7018b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 23.9 s (started: 2025-12-22 18:38:04 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pydantic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "collapsed": true,
        "id": "f8OhAnIKXhf-",
        "outputId": "c94bff8b-4d93-4910-a4df-e9ed50494700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.12.3)\n",
            "Collecting pydantic\n",
            "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Collecting pydantic-core==2.41.5 (from pydantic)\n",
            "  Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n",
            "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.6/463.6 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydantic-core, pydantic\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.41.4\n",
            "    Uninstalling pydantic_core-2.41.4:\n",
            "      Successfully uninstalled pydantic_core-2.41.4\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.12.3\n",
            "    Uninstalling pydantic-2.12.3:\n",
            "      Successfully uninstalled pydantic-2.12.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 5.50.0 requires pydantic<=2.12.3,>=2.0, but you have pydantic 2.12.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pydantic-2.12.5 pydantic-core-2.41.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydantic"
                ]
              },
              "id": "b21c4248be2e482d961aff16ce948f11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 19.2 s (started: 2025-12-22 18:41:52 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-22T16:24:51.557351Z",
          "start_time": "2025-12-22T16:24:51.192580Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEhrpT9IHfBP",
        "outputId": "f5149151-0921-4060-ab92-da53f72d999b",
        "collapsed": true
      },
      "source": [
        "# Load ipython-autotime to see how long each cell take to run\n",
        "# No changes needed in this cell\n",
        "\n",
        "!pip install -q ipython-autotime\n",
        "%load_ext autotime"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 371 µs (started: 2025-12-22 18:42:46 +00:00)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OWcumPwHfBQ",
        "outputId": "54d58d9a-8e5d-4417-aaa5-811214320846",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec 22 18:42:46 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "time: 215 ms (started: 2025-12-22 18:42:46 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Verify we have enough GPU memory to run this project (at least 15360MiB)\n",
        "# No changes needed in this cell\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "0d6a2ea0a4fe4f11beaa92fc59517763",
            "a241eb57c5a9490eb8fb77e2912b3546",
            "58afcc301e294a21a758b82b8ab711ce",
            "d7f01ca218cb4a06bc2c012cd484ec2a",
            "4a257fce2aa544fb839e1c49aaf7c1c6",
            "b880135e3b6342249c428a00526c3536",
            "ae1a3fbf406f4e589fd62cf59b8376ac",
            "8b1b723f38184b849ef51ea31cf4680a",
            "d3cd87d2a6c0410a99783bcc5141e9ed",
            "50d1ee387c1845b19491b17391b60bd8",
            "ae11e89d588642429f7ababde6b55481",
            "0d421ad0da914ca4876dfce2b630dda7",
            "58e7a6a503bf475688eddfb220f36dd9",
            "2acac5dbbb994ce896c5225731db4312",
            "446274b77b9c43ab8e12d87be83d7c94",
            "f586a3d36b6a46e3a9b2dd3abcdb3115",
            "c517e6a097d24946a04030b823aa7b22",
            "04d82b29d8064ad8acb63690f4e7d8c9",
            "17fa574a6fff493fadb0d59fda8b6ec8",
            "116785b6cf9e4b1b8f31903e26f91a5e",
            "3283396db6f04e8ca947d17d812c0258",
            "5d51d2bde0044acb803bd900848a067b",
            "7b15f2cf9e39445cb7278c7a36de2fc0",
            "d236f2182ea445baadf712aeeeefd0ff",
            "8b6e7ef252f04a44995a92364bee6c98",
            "662e56eb250c4504bf5f9e6a3b76644f",
            "597ccff8a42547fa997578a637d44870",
            "5363d3dcafd64661be1897615078a9d5",
            "06d3db43480f43fe9d96fc705783c37f",
            "b3476755500c4502bb4a7645887beb61",
            "f7211648a3764f11835c8572ed7fb183",
            "928fc12e232b41d39789894bcda30638",
            "3f74dd311a194a6e9fd68f4bdb4e0411",
            "e1205492a99c4d99980844793c76750c",
            "158c419b4980404f8d7fe2f56a1a6466",
            "f1c2ccb785a142bb8367733ce687a967",
            "cd168c57025340299e9e175164f844e7",
            "caf7f31f0e864a289bcbf2b2edc70524",
            "a83cec22ffa9452e82a13196418bd08d",
            "593d47aedcec4a59925d97ac279713db",
            "1e65e71889d14e47a83a969c3cb79632",
            "9a5b5b469b9b4dee8f07d9d348c7204e",
            "e0023acb766f478b8ddb70b7c2692143",
            "13302c1cea63450184f2ae7d43fb68f1",
            "65ae6380def843bfbc5502ba29875416",
            "f273eb103c564193b84933dc7293187c",
            "5fe79d1e81ab4d5c9a4f8d35d27243de",
            "b17ccf312e4b494e9144ad4eaf7eab42",
            "dc07558c40e94328b891d30c4ebcac8c",
            "30be81ea34fb43b3a82f161a7e030680",
            "f56390f301c340fdb6c3224b0ed91927",
            "2eca1e8e5e0d4ce6bff9e87367381b21",
            "9b31a1b8b7f747eca7e8bdad0f1dc966",
            "3573c80bc33e458fa603b9ccc90beecb",
            "f7c131024ecf44b08277488f338eab0f",
            "65c48e3422064478a198eaba17a17475",
            "f8874128e0474fd3a4b4b44b40b3d6df",
            "9a4e52149a95448e8cefb42ab83672a2",
            "403bea2c9bcf4e7dba35b2bd8876e1ff",
            "51e64cf1403b4045999a447e8d40caaf",
            "8be6a599f4f9402ca8ec35cdd4c8d07c",
            "4750ca14fd8b44a4bddd731f26a134ce",
            "e8cec81bdcc14a65817b136fbfc646b9",
            "5a665d260c6c486f826d207bf225b126",
            "911791bbc14d4b94b1ea6f5716b8d3b0",
            "d964790e73e94a23b9c5460859c4c5ed",
            "4ce3910074fb4acca5fc387ada827bfd",
            "fe80d7c0cec642589ecaf2305fa7596f",
            "695b480254cd4667ad655f8c693c352b",
            "a1ae42af868248b788e4b77d97eac30a",
            "bde27c81074e4713823ff47cf92dbfb0",
            "876eee7276f044faa22f2240bdbbc2d7",
            "96ce796505e94c43a37cce9de7be5c5a",
            "fe37bc0a19f24c0099874b16493f5308",
            "510cc381934649ca8b21bcfe3e27805d",
            "bbc2616b6c02499fb45540f4eaf8aa50",
            "5b650d688c574f67b43f9879766be302"
          ]
        },
        "collapsed": true,
        "id": "R4ixulovHfBR",
        "outputId": "63df198b-126b-4d9f-e19e-0a117188b57b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.12.8: Fast Qwen2 patching. Transformers: 4.57.3. vLLM: 0.13.0.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post1. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.36G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d6a2ea0a4fe4f11beaa92fc59517763"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d421ad0da914ca4876dfce2b630dda7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b15f2cf9e39445cb7278c7a36de2fc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1205492a99c4d99980844793c76750c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65ae6380def843bfbc5502ba29875416"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65c48e3422064478a198eaba17a17475"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ce3910074fb4acca5fc387ada827bfd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.12.8 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1min 10s (started: 2025-12-22 18:45:12 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Load the `Qwen 2.5 3B Instruct`, and set parameters for the project\n",
        "# The first time unsloth is imported, it will do its magic and patch the modules\n",
        "# it works with. This may 2-5 minutes.\n",
        "\n",
        "import unsloth\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "max_seq_length = 384  # Increase if you get errors about the sequence length\n",
        "\n",
        "# Set the LoRA rank to an appropriate value\n",
        "# Read about setting LoRA rank:\n",
        "# https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide\n",
        "# Setting lora_rank to 64 provides a good balance between model capacity and memory efficiency.\n",
        "# A higher rank allows the model to learn more complex patterns but uses more memory.\n",
        "# For this task (letter counting with reasoning), 64 is sufficient for good performance.\n",
        "lora_rank = 64\n",
        "\n",
        "# Load the Instruct model in 4-bit mode\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"Qwen/Qwen2.5-3B-Instruct\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    load_in_4bit=True,  # We'll use quantization!\n",
        "    fast_inference=False,  # This uses vllm for faster inference\n",
        "    max_lora_rank=lora_rank,\n",
        "    disable_log_stats = True,\n",
        "    gpu_memory_utilization=0.5,  # You can reduce this if you get an memory error\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=lora_rank,\n",
        "    target_modules=[\n",
        "        # Read about choosing adapters for LoRA:\n",
        "        # https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide\n",
        "        # Targeting all key linear layers in attention and MLP blocks for comprehensive adaptation.\n",
        "        # This ensures the model can learn the reasoning task effectively across all transformer components.\n",
        "        \"q_proj\",    # Query projection in attention\n",
        "        \"k_proj\",    # Key projection in attention\n",
        "        \"v_proj\",    # Value projection in attention\n",
        "        \"o_proj\",    # Output projection in attention\n",
        "        \"gate_proj\", # Gate projection in MLP\n",
        "        \"up_proj\",   # Up projection in MLP\n",
        "        \"down_proj\", # Down projection in MLP\n",
        "    ],\n",
        "    lora_alpha=lora_rank,\n",
        "    use_gradient_checkpointing=\"unsloth\",  # Unsloth enables longer contexts\n",
        "    # See: https://github.com/unslothai/unsloth\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT2XJ2uwHfBR"
      },
      "source": [
        "## Try Prompt Engineering to Count Letters\n",
        "\n",
        "Let's work on the system prompt a little to see if we can get the model to count the number of the letter `g` in `engage`.\n",
        "\n",
        "\n",
        "Here you must:\n",
        "* Write clear instructions\n",
        "* Break the problem down into steps (Chain-of-Thought prompting)\n",
        "* Provide at least one example for the model to follow (Few-shot prompting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZHoHwWrHfBR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91619778-5cad-499e-d523-334a09e02b9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TEXT FOR COMPLETION ===\n",
            "<|im_start|>system\n",
            "<|im_end|>\n",
            "<|im_start|>user\n",
            "How many of the letter \"g\" are there in the word \"engage\"<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n",
            "=== GENERATED OUTPUT ===\n",
            "There is 1 letter \"g\" in the word \"engage\".\n",
            "time: 3.17 s (started: 2025-12-22 18:54:15 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# First, let's see what happens when we have a blank system prompt\n",
        "# No changes needed in this cell\n",
        "SYSTEM_PROMPT = \"\"\"\"\"\"\n",
        "USER_PROMPT = 'How many of the letter \"g\" are there in the word \"engage\"'\n",
        "\n",
        "# Convert the chat messages to a single string so the model can complete it\n",
        "text_for_completion = tokenizer.apply_chat_template(\n",
        "    conversation=[\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": USER_PROMPT,\n",
        "        },\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True,\n",
        ")\n",
        "\n",
        "from vllm import SamplingParams\n",
        "\n",
        "# Set the LLM sampling parameters\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    max_tokens=2048,\n",
        ")\n",
        "\n",
        "# Generate the text completion\n",
        "\n",
        "inputs = tokenizer([text_for_completion], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "output = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=2048,\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    use_cache=True,\n",
        ")\n",
        "# Decode the output\n",
        "generated_text = tokenizer.batch_decode(output)[0]\n",
        "# To remove the prompt and keep only the response:\n",
        "response = generated_text.split(\"<|begin_of_text|>\")[-1].split(\"assistant\\n\")[-1]\n",
        "\n",
        "\n",
        "# Print the text input for the model and the model's output\n",
        "print(\"=== TEXT FOR COMPLETION ===\")\n",
        "print(text_for_completion)\n",
        "\n",
        "# 1. Generate as you did (already creates 'output' tensor)\n",
        "# 2. Decode the tensor into text\n",
        "# skip_special_tokens=True removes <|im_start|>, <|im_end|>, etc.\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# 3. Extract only the assistant's part\n",
        "# The prompt is included in 'output', so we split it to get just the reply\n",
        "response = decoded_output.split(\"assistant\")[-1].strip()\n",
        "\n",
        "print(\"=== GENERATED OUTPUT ===\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pNvGYJCHfBR"
      },
      "source": [
        "Without any prompting the model will generate an output such as this:\n",
        "\n",
        "```\n",
        "=== GENERATED OUTPUT ===\n",
        "There is one letter \"g\" in the word \"engage\".\n",
        "```\n",
        "\n",
        "Now let's work on the system prompt to help the model break this problem down into steps, which might help it get the right answer (2 `g`'s in `engage`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0FuzGBsHfBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac952bf2-28c4-4fb9-b0ae-eafac09b45ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TEXT FOR COMPLETION ===\n",
            "<|im_start|>system\n",
            "You are an assistant that counts letters in words. You should think step-by-step and use letter-by-letter spelling.\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "<reasoning>\n",
            "Letter-by-letter spelling:\n",
            "1. [letter] - [count] [target letter]'s so far\n",
            "2. [letter] - [count] [target letter]'s so far\n",
            "...\n",
            "\n",
            "The letter \"[target letter]\" appears [count] times in the word \"[word]\".\n",
            "</reasoning>\n",
            "<answer>\n",
            "[count]\n",
            "</answer>\n",
            "\n",
            "Example:\n",
            "Question: How many of the letter \"o\" are there in the word \"room\"\n",
            "<reasoning>\n",
            "Letter-by-letter spelling:\n",
            "1. r - 0 o's so far\n",
            "2. o - 1 o's so far\n",
            "3. o - 2 o's so far\n",
            "4. m - 2 o's so far\n",
            "\n",
            "The letter \"o\" appears 2 times in the word \"room\".\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "\n",
            "Now answer the question using the same format.\n",
            "<|im_end|>\n",
            "<|im_start|>user\n",
            "How many of the letter \"g\" are there in the word \"engage\"<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n",
            "=== GENERATED OUTPUT ===\n",
            "<reasoning>\n",
            "Letter-by-letter spelling:\n",
            "1. a - 0 g's so far\n",
            "2. n - 0 g's so far\n",
            "3. g - 1 g's so far\n",
            "4. e - 1 g's so far\n",
            "5. n - 1 g's so far\n",
            "6. g - 2 g's so far\n",
            "7. e - 2 g's so far\n",
            "\n",
            "The letter \"g\" appears 2 times in the word \"engage\".\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "time: 11 s (started: 2025-12-22 18:56:18 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Let's work on a new system prompt that will help the model break this problem\n",
        "# down into steps, for example, using \"letter-by-letter\" spelling.\n",
        "\n",
        "# Use a CoT prompt with at least one example\n",
        "SYSTEM_PROMPT = \"\"\"You are an assistant that counts letters in words. You should think step-by-step and use letter-by-letter spelling.\n",
        "\n",
        "Follow this format:\n",
        "\n",
        "<reasoning>\n",
        "Letter-by-letter spelling:\n",
        "1. [letter] - [count] [target letter]'s so far\n",
        "2. [letter] - [count] [target letter]'s so far\n",
        "...\n",
        "\n",
        "The letter \"[target letter]\" appears [count] times in the word \"[word]\".\n",
        "</reasoning>\n",
        "<answer>\n",
        "[count]\n",
        "</answer>\n",
        "\n",
        "Example:\n",
        "Question: How many of the letter \"o\" are there in the word \"room\"\n",
        "<reasoning>\n",
        "Letter-by-letter spelling:\n",
        "1. r - 0 o's so far\n",
        "2. o - 1 o's so far\n",
        "3. o - 2 o's so far\n",
        "4. m - 2 o's so far\n",
        "\n",
        "The letter \"o\" appears 2 times in the word \"room\".\n",
        "</reasoning>\n",
        "<answer>\n",
        "2\n",
        "</answer>\n",
        "\n",
        "Now answer the question using the same format.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "USER_PROMPT = 'How many of the letter \"g\" are there in the word \"engage\"'\n",
        "\n",
        "# Convert the chat messages to a single string so the model can complete it\n",
        "text_for_completion = tokenizer.apply_chat_template(\n",
        "    conversation=[\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": USER_PROMPT,\n",
        "        },\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True,\n",
        ")\n",
        "\n",
        "from vllm import SamplingParams\n",
        "\n",
        "# Set the LLM sampling parameters\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    max_tokens=2048,\n",
        ")\n",
        "\n",
        "# Generate the text completion\n",
        "inputs = tokenizer([text_for_completion], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "output = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=2048,\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    use_cache=True,\n",
        ")\n",
        "\n",
        "# Print the text input for the model and the model's output\n",
        "print(\"=== TEXT FOR COMPLETION ===\")\n",
        "print(text_for_completion)\n",
        "\n",
        "# 1. Generate as you did (already creates 'output' tensor)\n",
        "# 2. Decode the tensor into text\n",
        "# skip_special_tokens=True removes <|im_start|>, <|im_end|>, etc.\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# 3. Extract only the assistant's part\n",
        "# The prompt is included in 'output', so we split it to get just the reply\n",
        "response = decoded_output.split(\"assistant\")[-1].strip()\n",
        "\n",
        "print(\"=== GENERATED OUTPUT ===\")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv5YtQeIHfBT"
      },
      "source": [
        "Did your new prompt get the right answer? Did the model follow all of your instructions?\n",
        "\n",
        "Maybe yes, maybe no. Either way, we'll want the model to reliably complete this challenge. So let's use GRPO to help it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpxonqZZHfBU"
      },
      "source": [
        "## Create a letter-counting dataset\n",
        "\n",
        "To train a model, we'll first need to create a dataset. We'll use the HuggingFace `datasets` package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cgzu9PX6HfBU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "227468b2-291e-4939-a95f-8744eff77a50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['idea',\n",
              " 'glow',\n",
              " 'rust',\n",
              " 'maze',\n",
              " 'echo',\n",
              " 'wisp',\n",
              " 'veto',\n",
              " 'lush',\n",
              " 'gaze',\n",
              " 'knit']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.82 ms (started: 2025-12-22 18:56:50 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Create a list of words of different lengths\n",
        "# No changes are needed in this cell.\n",
        "\n",
        "ALL_WORDS = [\n",
        "    \"idea\",\n",
        "    \"glow\",\n",
        "    \"rust\",\n",
        "    \"maze\",\n",
        "    \"echo\",\n",
        "    \"wisp\",\n",
        "    \"veto\",\n",
        "    \"lush\",\n",
        "    \"gaze\",\n",
        "    \"knit\",\n",
        "    \"fume\",\n",
        "    \"plow\",\n",
        "    \"void\",\n",
        "    \"oath\",\n",
        "    \"grim\",\n",
        "    \"crisp\",\n",
        "    \"lunar\",\n",
        "    \"fable\",\n",
        "    \"quest\",\n",
        "    \"verge\",\n",
        "    \"brawn\",\n",
        "    \"elude\",\n",
        "    \"aisle\",\n",
        "    \"ember\",\n",
        "    \"crave\",\n",
        "    \"ivory\",\n",
        "    \"mirth\",\n",
        "    \"knack\",\n",
        "    \"wryly\",\n",
        "    \"onset\",\n",
        "    \"mosaic\",\n",
        "    \"velvet\",\n",
        "    \"sphinx\",\n",
        "    \"radius\",\n",
        "    \"summit\",\n",
        "    \"banner\",\n",
        "    \"cipher\",\n",
        "    \"glisten\",\n",
        "    \"mantle\",\n",
        "    \"scarab\",\n",
        "    \"expose\",\n",
        "    \"fathom\",\n",
        "    \"tavern\",\n",
        "    \"fusion\",\n",
        "    \"relish\",\n",
        "    \"lantern\",\n",
        "    \"enchant\",\n",
        "    \"torrent\",\n",
        "    \"capture\",\n",
        "    \"orchard\",\n",
        "    \"eclipse\",\n",
        "    \"frescos\",\n",
        "    \"triumph\",\n",
        "    \"absolve\",\n",
        "    \"gossipy\",\n",
        "    \"prelude\",\n",
        "    \"whistle\",\n",
        "    \"resolve\",\n",
        "    \"zealous\",\n",
        "    \"mirage\",\n",
        "    \"aperture\",\n",
        "    \"sapphire\",\n",
        "]\n",
        "\n",
        "print(len(ALL_WORDS))\n",
        "\n",
        "ALL_WORDS[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpuz4nNgHfBV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "adefb166bc4e4afbb36c2797087d0d07",
            "163893b19286416782630eb7b28659e4",
            "512bdb3486a442d5a5021788e4adeca4",
            "cddf003ae2e545c0b705d7413b5589c1",
            "5a0c73753e894c02ab949ab23355baca",
            "cccce94d8cd948c28442a8ac4ea87d93",
            "cf9b7eb6474043108366ad4ce683d181",
            "2c4552bca0014b97b82b68670c46b5ab",
            "de0b1cd793aa4029a578664c248d5a63",
            "bf58e70db2de4ff08ae90102721e4ce7",
            "17a620c6ac1a4693927696b399b586d0"
          ]
        },
        "collapsed": true,
        "outputId": "b0139f70-515c-4a78-cf46-03ed1ea76682"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "adefb166bc4e4afbb36c2797087d0d07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'words': 'idea', 'letters': 'a', 'counts': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 206 ms (started: 2025-12-22 18:57:12 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Create the dataset as a Hugging Face Dataset using Dataset.from_generator\n",
        "# No changes needed in this cell\n",
        "\n",
        "from datasets import Dataset\n",
        "import random\n",
        "\n",
        "\n",
        "# Go through the letters from the words (as well as letters not in the words),\n",
        "# and create a labelled dataset with all the different combinations.\n",
        "# For example for the word gaze:\n",
        "# 1. How many i's are in idea? <-- count should be 1\n",
        "# 2. How many d's are in idea? <-- count should be 1\n",
        "# 3. How many e's are in idea? <-- count should be 1\n",
        "# 4. How many a's are in idea? <-- count should be 1\n",
        "# 5. How many b's are in idea? <-- a letter not in word (count should be zero)\n",
        "def generate_records():\n",
        "    for word in ALL_WORDS:\n",
        "        for letter in sorted(set(word)):\n",
        "            yield {\"words\": word, \"letters\": letter, \"counts\": word.count(letter)}\n",
        "\n",
        "        # pick random letters not in the word\n",
        "        num_letters_not_in_word_left = int(len(word) // 7 + 1)\n",
        "\n",
        "        random.seed(hash(word))\n",
        "\n",
        "        all_letters = list(\"abcdefghijklmnopqrstuvwxyz\")\n",
        "\n",
        "        random.shuffle(all_letters)\n",
        "        for letter in all_letters:\n",
        "            if letter not in word:\n",
        "                yield {\"words\": word, \"letters\": letter, \"counts\": 0}\n",
        "                num_letters_not_in_word_left -= 1\n",
        "            if num_letters_not_in_word_left == 0:\n",
        "                break\n",
        "\n",
        "\n",
        "ds = Dataset.from_generator(generate_records)\n",
        "\n",
        "# Show the first item\n",
        "ds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_UBo7eLHfBV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214,
          "referenced_widgets": [
            "78ea5175bae64de8b74bb11c12d5dd92",
            "a5a24686257949b497fb37b44f2c41fa",
            "1fc840809a2b4dc2ba78e6489fe19a02",
            "7936147c93f64490ac9ff784a2e4b140",
            "be867cdf6f5d4fe69d7de7e5559a9e36",
            "fb9dbfb84b44484ca0da2b7804ca7c72",
            "ed28f1a051a9482c93cf720f51f21aed",
            "4b778a119f474f43944a150940a1fa11",
            "d8b386a9e4154b288ce1b477d1c754e6",
            "41d97dd90e2849c39c632c0385a494a9",
            "a573f22e7c094ed88a41f9d46b274e0d"
          ]
        },
        "collapsed": true,
        "outputId": "12d1599e-b0e0-40d4-e086-a20305519096"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/401 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78ea5175bae64de8b74bb11c12d5dd92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'words': 'idea',\n",
              " 'letters': 'a',\n",
              " 'counts': 1,\n",
              " 'prompt': [{'content': \"\\nRespond in the following format:\\n<reasoning>\\nCounting the number of [letter_to_count]'s in the word [word]\\n1. [first letter] - [count of requested letter so far] so far\\n2. [second letter] - [count of requested letter so far] so far\\n...\\n</reasoning>\\n<answer>\\n[number]\\n</answer>\\n\",\n",
              "   'role': 'system'},\n",
              "  {'content': 'How many of the letter \"a\" are there in the word \"idea\"',\n",
              "   'role': 'user'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 65.3 ms (started: 2025-12-22 18:57:29 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Add the entire prompt (system + user) and the answer to the dataset\n",
        "# We'll use a prompt that spells out the word letter-by-letter\n",
        "# No changes needed in this cell\n",
        "\n",
        "import re\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Simple CoT prompt (zero-shot)\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "Respond in the following format:\n",
        "<reasoning>\n",
        "Counting the number of [letter_to_count]'s in the word [word]\n",
        "1. [first letter] - [count of requested letter so far] so far\n",
        "2. [second letter] - [count of requested letter so far] so far\n",
        "...\n",
        "</reasoning>\n",
        "<answer>\n",
        "[number]\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "ds = ds.map(\n",
        "    lambda x: {  # type: ignore\n",
        "        \"prompt\": [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": 'How many of the letter \"{}\" are there in the word \"{}\"'.format(\n",
        "                    x[\"letters\"], x[\"words\"]\n",
        "                ),\n",
        "            },\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "ds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7gQ4d8EHfBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "c60e907b-7ed2-4f50-f5a6-d842f927381b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== GENERATED OUTPUT ===\n",
            "<reasoning>\n",
            "Letter-by-letter spelling:\n",
            "1. a - 0 g's so far\n",
            "2. n - 0 g's so far\n",
            "3. g - 1 g's so far\n",
            "4. e - 1 g's so far\n",
            "5. n - 1 g's so far\n",
            "6. g - 2 g's so far\n",
            "7. e - 2 g's so far\n",
            "\n",
            "The letter \"g\" appears 2 times in the word \"engage\".\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "time: 9.43 s (started: 2025-12-22 18:59:40 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Let's see how well the model runs out-of-the-box\n",
        "# No changes needed in this cell\n",
        "\n",
        "text = tokenizer.apply_chat_template(\n",
        "    ds[0][\"prompt\"], tokenize=False, add_generation_prompt=True\n",
        ")\n",
        "\n",
        "from vllm import SamplingParams\n",
        "\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    max_tokens=1024,\n",
        ")\n",
        "\n",
        "output = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=2048,\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    use_cache=True,\n",
        ")\n",
        "\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "response = decoded_output.split(\"assistant\")[-1].strip()\n",
        "\n",
        "print(\"=== GENERATED OUTPUT ===\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I23TW00RHfBV"
      },
      "source": [
        "## Create Reward Functions\n",
        "\n",
        "One goal of creating reward functions is to guide the model toward behaviors that help it reach its goal (counting the occurrences of a letter within a word) more easily. Since there is more than one way to carry out any step-by-step task (e.g. whether or not you use bullet points to separate your steps), there's a bit of judgement involved in choosing what behaviors to reward, i.e. how do we provide partial credit or \"shape\" our rewards?\n",
        "\n",
        "In this case we will encourage the model to (whether or not this structure is best):\n",
        "* use numbers for bullet points when spelling out the word\n",
        "* to spell the word correctly\n",
        "* to count the requested letter correctly\n",
        "* to use the requested reasoning format\n",
        "* to get the final answer correct.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql1mYutUHfBW"
      },
      "source": [
        "### Numbering reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP_PvdvsHfBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50648249-a9ed-428f-cd7b-aa3a9870d541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.5, 0.25]\n",
            "time: 4.58 ms (started: 2025-12-22 19:01:00 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Let's work on a function that the numbering in the bullet points is correct\n",
        "# When using GRPO, we lean on reward functions that are relatively easy to\n",
        "# compute, thus removing the need to have a second large model just for\n",
        "# evaluation.\n",
        "# In this case, we'll use regular expressions quite a bit.\n",
        "\n",
        "\n",
        "def extract_letter_numbering(response):\n",
        "    \"\"\"Extract the numbers at the beginning of the line\n",
        "\n",
        "    Example:\n",
        "    1. g - 1 so far\n",
        "    2. o - 1 so far\n",
        "    3. a - 2 so far\n",
        "    4. a - 2 so far\n",
        "    5. l - 2 so far\n",
        "    returns [1, 2, 3, 4, 5]\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    # We use a regular expression to find lines of the form:\n",
        "    # '\\n[number]. [letter]'\n",
        "    pattern = r\"\\n(\\d+). [a-z]\"\n",
        "\n",
        "    # Use `re` to find all matches of the pattern in the response\n",
        "    matches = re.findall(pattern, response, re.IGNORECASE)\n",
        "    if matches:\n",
        "        return [int(m) for m in matches]\n",
        "    return []\n",
        "\n",
        "\n",
        "assert extract_letter_numbering(\n",
        "    \"\"\"\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. a - 2 so far\n",
        "5. l - 2 so far\n",
        "\"\"\"\n",
        ") == [1, 2, 3, 4, 5]\n",
        "\n",
        "\n",
        "def numbering_reward_func(completions, words, **kwargs) -> list[float]:\n",
        "    \"\"\"Provides a reward for getting the numbering at the beginning of the line correct\n",
        "\n",
        "    1. g - 1 so far <-- Good in-order numbering\n",
        "    2. o - 1 so far <-- Good in-order numbering\n",
        "    3. a - 2 so far <-- Good in-order numbering\n",
        "    3. l - 2 so far <-- Bad numbering, out-of-order, 3 should be 4\n",
        "    1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "    1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "\n",
        "    \"\"\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    res = []\n",
        "    for response, word in zip(responses, words):\n",
        "        reward = 0\n",
        "\n",
        "        for ix, spell_number in enumerate(extract_letter_numbering(response)):\n",
        "            line_number = ix + 1\n",
        "\n",
        "            # Get points for in-order numbering\n",
        "            if spell_number == line_number:\n",
        "                # Provide a reward for in-order numbering\n",
        "                reward += 0.5\n",
        "            # Otherwise lose points\n",
        "            else:\n",
        "                # Penalize out-of-order numbering\n",
        "                reward -= 0.5\n",
        "\n",
        "            # Lose extra points for continuing beyond the length of the word\n",
        "            if line_number > len(word):  # We use the index of the line\n",
        "                # Penalize continuing beyond the word length\n",
        "                reward -= 1.0\n",
        "\n",
        "        res.append(reward / len(word))\n",
        "    return res\n",
        "\n",
        "\n",
        "res = numbering_reward_func(\n",
        "    completions=[\n",
        "        [\n",
        "            {  # Worse response\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far <-- Good in-order numbering\n",
        "2. o - 1 so far <-- Good in-order numbering\n",
        "3. a - 2 so far <-- Good in-order numbering\n",
        "3. l - 2 so far <-- Bad numbering, out-of-order, 3 should be 4\n",
        "1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            },\n",
        "        ],\n",
        "        [\n",
        "            {  # Better response\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far <-- Good in-order numbering\n",
        "2. o - 1 so far <-- Good in-order numbering\n",
        "3. a - 2 so far <-- Good in-order numbering\n",
        "3. l - 2 so far <-- Bad numbering, out-of-order, 3 should be 4\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            },\n",
        "        ],\n",
        "    ],\n",
        "    words=[\"goal\", \"goal\"],\n",
        ")\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm4agJvqHfBW"
      },
      "source": [
        "### Spelling reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLmOTGNpHfBX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aa469e2-4791-4b7c-de89-ea70b20190ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.5, 2.0]\n",
            "time: 2.89 ms (started: 2025-12-22 19:01:13 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Reward correct spelling of the word\n",
        "\n",
        "\n",
        "def extract_spelling(response):\n",
        "    \"\"\"Extract the spelling from the response\n",
        "\n",
        "    Example:\n",
        "    1. g - 1 so far\n",
        "    2. o - 1 so far\n",
        "    3. a - 2 so far\n",
        "    3. l - 2 so far\n",
        "    5. l - 2 so far\n",
        "    Returns \"goall\"\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    pattern = r\"\\n\\d+. ([a-z])\"\n",
        "    matches = re.findall(pattern, response, flags=re.IGNORECASE)\n",
        "    if matches:\n",
        "        return \"\".join([m for m in matches])\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "extract_spelling(\n",
        "    \"\"\"Here is a letter by letter spelling:\n",
        "\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "3. l - 2 so far\n",
        "5. l - 2 so far\n",
        "\"\"\"\n",
        ") == \"goall\"\n",
        "\n",
        "\n",
        "def spelling_reward_func(completions, words, **kwargs) -> list[float]:\n",
        "    \"\"\"A spelling reward function.\"\"\"\n",
        "    from collections import Counter\n",
        "\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    res = []\n",
        "\n",
        "    for word, response in zip(words, responses):\n",
        "        reward = 0.0\n",
        "\n",
        "        spelling = extract_spelling(response)\n",
        "\n",
        "        # Provide a reward for exactly correct spelling\n",
        "        if spelling == word:\n",
        "            reward += 2.0\n",
        "\n",
        "        # Provide a penalty for each letter of difference in length\n",
        "        reward -= 0.5 * abs(len(spelling) - len(word))\n",
        "\n",
        "        # Provide a penalty for each letter that is not in the target word\n",
        "        spelling_counter = Counter(spelling)\n",
        "        word_counter = Counter(word)\n",
        "        for letter, count in spelling_counter.items():\n",
        "            extra_count = max(0, count - word_counter.get(letter, 0))\n",
        "            reward -= 1.0 * extra_count\n",
        "\n",
        "        # Provide a penalty for each letter that is in the target word but not in the response\n",
        "        for letter, count in word_counter.items():\n",
        "            missing_count = max(0, count - spelling_counter.get(letter, 0))\n",
        "            reward -= 0.5 * missing_count\n",
        "\n",
        "        res.append(reward)\n",
        "    return res\n",
        "\n",
        "\n",
        "res = spelling_reward_func(\n",
        "    completions=[\n",
        "        [  # Worse response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. l - 2 so far\n",
        "5. l - 2 so far\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "        [  # Better Response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. l - 2 so far\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "    ],\n",
        "    words=[\"goal\", \"goal\"],\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFzU-PDMHfBX"
      },
      "source": [
        "### Counting reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jxpu9Y1aHfBX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d2cc449-4d76-4576-fea9-6532fe0c4a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.6, 1.0]\n",
            "time: 3.07 ms (started: 2025-12-22 19:01:28 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Let's reward the model for properly counting the occurrences of a letter in a word\n",
        "\n",
        "\n",
        "def get_resp_letters_and_counts(response):\n",
        "    \"\"\"Extract the letters and counts from the response\n",
        "\n",
        "    Example:\n",
        "    1. g - 1 so far\n",
        "    2. o - 1 so far\n",
        "    3. a - 2 so far\n",
        "    4. a - 2 so far\n",
        "    5. l - 2 so far\n",
        "    returns [('g', 1), ('o', 1), ('a', 2), ('a', 2), ('l', 2)]\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    pattern = r\"\\n(\\d+)\\. ([a-z])\\D*(\\d+)\"\n",
        "\n",
        "    # Find strings matching e.g. \"2. a - 2 so far\"\n",
        "    matches = re.findall(pattern, response, flags=re.IGNORECASE)\n",
        "\n",
        "    if not matches:\n",
        "        return []\n",
        "\n",
        "    return [\n",
        "        (matched_letter, matched_count_so_far)\n",
        "        for _, matched_letter, matched_count_so_far in matches\n",
        "    ]\n",
        "\n",
        "\n",
        "assert get_resp_letters_and_counts(\n",
        "    \"\"\"\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. a - 2 so far\n",
        "5. l - 2 so far\n",
        "\"\"\"\n",
        ") == [(\"g\", \"1\"), (\"o\", \"1\"), (\"a\", \"2\"), (\"a\", \"2\"), (\"l\", \"2\")]\n",
        "\n",
        "\n",
        "def counting_reward_func(completions, letters, **kwargs) -> list[float]:\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    res = []\n",
        "\n",
        "    # Iterate over each of the letter-response pairs\n",
        "    for letter, response in zip(letters, responses):\n",
        "        reward = 0\n",
        "\n",
        "        letters_and_counts = get_resp_letters_and_counts(response)\n",
        "\n",
        "        # If there are no matches, provide a negative reward\n",
        "        if not letters_and_counts:\n",
        "            res.append(-1)\n",
        "            continue\n",
        "\n",
        "        # Start counting the matching letters\n",
        "        actual_count = 0\n",
        "        for resp_letter, resp_count in letters_and_counts:\n",
        "            # If there's a match, count the letter\n",
        "            if letter == resp_letter:\n",
        "                actual_count += 1\n",
        "\n",
        "            # If the count is accurate, add a reward, else subtract a reward\n",
        "            if int(resp_count) == actual_count:\n",
        "                reward += 1.0\n",
        "            else:\n",
        "                reward -= 1.0\n",
        "\n",
        "        # Return the reward normalized by the length of the matches\n",
        "        res.append(reward / len(letters_and_counts))\n",
        "    return res\n",
        "\n",
        "\n",
        "res = counting_reward_func(\n",
        "    completions=[\n",
        "        [  # Worse response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\\nHere is a letter by letter spelling:\n",
        "\n",
        "1. g - 0 so far\n",
        "2. o - 0 so far\n",
        "3. a - 1 so far\n",
        "4. a - 2 so far\n",
        "5. l - 0 so far\n",
        "\n",
        "\\n</reasoning>\\n<answer>\\nThis is my answer.\\n</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "        [  # Better response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\\nHere is a letter by letter spelling:\n",
        "\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 1 so far\n",
        "4. a - 1 so far\n",
        "5. l - 1 so far\n",
        "\n",
        "\\n</reasoning>\\n<answer>\\nThis is my answer.\\n</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "    ],\n",
        "    letters=[\"g\", \"g\"],\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DNm_QXwHfBY"
      },
      "source": [
        "### Formatting reward functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmhMJwB0HfBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bbc4339-dca7-40b0-80da-51ed62647f26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 1.0]\n",
            "time: 2.25 ms (started: 2025-12-22 19:01:39 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Reward the model for providing the response in a specific format\n",
        "\n",
        "import re\n",
        "\n",
        "\n",
        "def extract_xml_answer(text: str) -> str:\n",
        "    \"\"\"Extracts the string between <answer> and </answer> tags.\"\"\"\n",
        "    pattern = r\"<answer>(.*?)</answer>\"\n",
        "    match = re.search(pattern, text, re.DOTALL)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "assert (\n",
        "    extract_xml_answer(\"\"\"\n",
        "<reasoning>\n",
        "This is my reasoning.\n",
        "</reasoning>\n",
        "<answer>SUPERCALIFRAGILISTICEXPIALIDOCIOUS</answer>\n",
        "\"\"\")\n",
        "    == \"SUPERCALIFRAGILISTICEXPIALIDOCIOUS\"\n",
        ")\n",
        "\n",
        "\n",
        "def format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"\\s*<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
        "\n",
        "    res = []\n",
        "\n",
        "    for completion in completions:\n",
        "        reward = 0.0\n",
        "\n",
        "        # Extract the response content\n",
        "        response = completion[0][\"content\"]\n",
        "\n",
        "        # Check if the response matches the pattern\n",
        "        match = re.match(pattern, response, flags=re.MULTILINE | re.DOTALL)\n",
        "\n",
        "        # If it matches, return 0.5, otherwise return 0.0\n",
        "        if match:\n",
        "            reward += 0.5\n",
        "\n",
        "        # Extract the answer from the response\n",
        "        extracted_answer = extract_xml_answer(response)\n",
        "\n",
        "        # If the answer is an integer, add 0.5 to the reward\n",
        "        if extracted_answer.isdigit():\n",
        "            reward += 0.5\n",
        "\n",
        "        res.append(reward)\n",
        "    return res\n",
        "\n",
        "\n",
        "res = format_reward_func(\n",
        "    completions=[\n",
        "        [{\"content\": \"This is my answer\"}],\n",
        "        [\n",
        "            {\n",
        "                \"content\": \"<reasoning>\\nThis is my reasoning.\\n</reasoning>\\n<answer>\\n3\\n</answer>\"\n",
        "            }\n",
        "        ],\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amFsiv3VHfBY"
      },
      "source": [
        "### Task correctness reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNktiqVKHfBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a529bd1-3d46-42fb-caf7-14a3d853e107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many...\n",
            "Answer: 0\n",
            "Response: <reasoning>.../reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "[-1.0, 2.0]\n",
            "time: 1.76 ms (started: 2025-12-22 19:01:44 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Reward the model for providing the correct answer\n",
        "\n",
        "\n",
        "def correct_answer_reward_func(prompts, completions, counts, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward the final answer if it is correct.\"\"\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "\n",
        "    # Print a nice summary of the first prompt, answer, and response to see while training\n",
        "    print(f\"\"\"\n",
        "{\"-\" * 20}\n",
        "Question: {prompts[0][-1][\"content\"]}\n",
        "Answer: {counts[0]}\n",
        "Response: {responses[0]}\n",
        "Extracted: {extracted_responses[0]}\n",
        "Correct: {str(extracted_responses[0]) == str(counts[0])}!\n",
        "    \"\"\")\n",
        "\n",
        "    res = [\n",
        "        # Provide reward for exactly correct answer\n",
        "        2.0 if str(r) == str(a) else -1.0\n",
        "        for r, a in zip(extracted_responses, counts)\n",
        "    ]\n",
        "    return res\n",
        "\n",
        "\n",
        "res = correct_answer_reward_func(\n",
        "    prompts=[\n",
        "        [{\"content\": \"\"\"How many...\"\"\"}],\n",
        "        [{\"content\": \"\"\"How many...\"\"\"}],\n",
        "    ],\n",
        "    completions=[\n",
        "        [{\"content\": \"\"\"<reasoning>.../reasoning>\\n<answer>\\n3\\n</answer>\"\"\"}],\n",
        "        [{\"content\": \"\"\"<reasoning>.../reasoning>\\n<answer>\\n3\\n</answer>\"\"\"}],\n",
        "    ],\n",
        "    letters=[\"g\", \"g\"],\n",
        "    counts=[0, 3],\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTp4EVToHfBZ"
      },
      "source": [
        "### List the reward functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9OwnrXTHfBZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81a00593-b100-4038-a601-11e925271cd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 979 µs (started: 2025-12-22 19:02:35 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# List out the reward functions we will use\n",
        "# No changes needed in this cell\n",
        "\n",
        "REWARD_FUNCS = [\n",
        "    numbering_reward_func,\n",
        "    spelling_reward_func,\n",
        "    counting_reward_func,\n",
        "    format_reward_func,\n",
        "    correct_answer_reward_func,\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNNE8tbXHfBZ"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "Now set up GRPO Trainer and configurations!\n",
        "\n",
        "As you run the trainer, the goal is to see the various `reward` columns increase.\n",
        "\n",
        "After 50 steps or more, you may notice some of the reward standard deviations begin to decrease, meaning that the different predictions are starting to converge on solutions that give similar rewards. If your model has learned the task, then you'll see the `correct_answer_reward_function` increase to its highest value (check the function to see what that is).\n",
        "\n",
        "Here is an example, which successfully converged on a higher reward. Note, the values you see here will probably be different from yours, especially if your reward amounts are different.\n",
        "\n",
        "| Step | Training Loss | reward   | reward_std | ... | kl      | rewards / correct_answer_reward_function / mean | rewards / correct_answer_reward_function / std |\n",
        "|------|---------------|----------|------------|-----|---------|------------------------------------------|-----------------------------------------|\n",
        "| 1    | 0.000000      | 7.961805 | 2.368493   | ... | 0.020369| 0.875000                                 | 1.024695                                |\n",
        "| 2    | 0.000000      | 7.937500 | 1.352467   | ... | 0.016483| 0.875000                                 | 1.024695                                |\n",
        "| 3    | 0.000000      | 1.894792 | 6.462189   | ... | 0.013677| 0.375000                                 | 0.806226                                |\n",
        "| ...  | ...           | ...      | ...        | ... | ...     | ...                                      | ...                                     |\n",
        "| 398  | 0.000100      | 13.000000| 0.000000   | ... | 0.088529| 2.000000                                 | 0.000000                                |\n",
        "| 399  | 0.000100      | 13.000000| 0.000000   | ... | 0.088617| 2.000000                                 | 0.000000                                |\n",
        "| 400  | 0.000100      | 13.000000| 0.000000   | ... | 0.096202| 2.000000                                 | 0.000000                                |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAPlShBsHfBZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e4d1a34-ba7e-4c0a-9fe9-fd4046ba8fe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.05 ms (started: 2025-12-22 19:02:42 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Fill in the GRPO Parameters we'll use throughout this project\n",
        "\n",
        "# Read about the GRPO params here https://huggingface.co/docs/trl/main/en/grpo_trainer\n",
        "COMMON_GRPO_TRAINING_PARAMS = dict(\n",
        "    # Set appropriate values for `learning_rate` and `beta`\n",
        "    # See: https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide\n",
        "    # See: https://huggingface.co/docs/trl/main/en/grpo_trainer\n",
        "    learning_rate=1e-6,\n",
        "    beta=0.0001,\n",
        "    # Set the batch size appropriately for your hardware. For GRPO there are a number of parameters to set.\n",
        "    # If you are not sure about your GPU, assume you have a T4. See the memory specs here:\n",
        "    # https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-product-literature/T4%20Product%20Brief.pdf\n",
        "    per_device_train_batch_size=16,  # per_device_train_batch_size / num_generations determines the number of simultaneous prompts to consider.\n",
        "    # Note: Set per_device_train_batch_size to at most 16 on the Vocareum T4 for best stability\n",
        "    num_generations=4,  # Determines the number of completions/generations to compute for each single prompt\n",
        "    gradient_accumulation_steps=1,  # This parameter allow us to consider multiple steps in a single optimization step\n",
        "    adam_beta1=0.9,\n",
        "    adam_beta2=0.99,\n",
        "    weight_decay=0.1,\n",
        "    warmup_ratio=0.1,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    optim=\"adamw_8bit\",\n",
        "    logging_steps=1,\n",
        "    max_prompt_length=256,\n",
        "    max_completion_length=200,\n",
        "    num_train_epochs=1,  # Set to 1 for a full training run\n",
        "    save_steps=250,\n",
        "    max_grad_norm=0.1,\n",
        "    report_to=\"none\",  # Setting this value lets us use Weights and Biases\n",
        "    output_dir=\"outputs\",\n",
        "    use_vllm=True,  # vll speeds up inference! See https://github.com/vllm-project/vllm\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTOXtHbhHfBa"
      },
      "source": [
        "### Quick train\n",
        "\n",
        "Let's train the model for just 5 steps (`max_steps=5`). As it runs we can double check we've set up our prompts correctly before running for a longer amount of time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gQ7mWawHfBa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "6152c40b-ee56-4f20-ac63-4585845b4595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: UnslothAlignPropTrainer is already patched.\n",
            "Unsloth: UnslothBCOTrainer is already patched.\n",
            "Unsloth: UnslothCPOTrainer is already patched.\n",
            "Unsloth: UnslothDDPOTrainer is already patched.\n",
            "Unsloth: UnslothDPOTrainer is already patched.\n",
            "Unsloth: UnslothGKDTrainer is already patched.\n",
            "Unsloth: UnslothGRPOTrainer is already patched.\n",
            "Unsloth: UnslothIterativeSFTTrainer is already patched.\n",
            "Unsloth: UnslothKTOTrainer is already patched.\n",
            "Unsloth: UnslothNashMDTrainer is already patched.\n",
            "Unsloth: UnslothOnlineDPOTrainer is already patched.\n",
            "Unsloth: UnslothORPOTrainer is already patched.\n",
            "Unsloth: UnslothPPOTrainer is already patched.\n",
            "Unsloth: UnslothPRMTrainer is already patched.\n",
            "Unsloth: UnslothRewardTrainer is already patched.\n",
            "Unsloth: UnslothRLOOTrainer is already patched.\n",
            "Unsloth: UnslothSFTTrainer is already patched.\n",
            "Unsloth: UnslothXPOTrainer is already patched.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 401 | Num Epochs = 1 | Total steps = 5\n",
            "O^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 1\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 1 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 119,734,272 of 3,205,672,960 (3.74% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"glisten\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word glisten\n",
            "1. g - 1 so far\n",
            "2. l - 1 so far\n",
            "3. i - 1 so far\n",
            "4. s - 1 so far\n",
            "5. t - 1 so far\n",
            "6. e - 1 so far\n",
            "7. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 03:45, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completions / mean_length</th>\n",
              "      <th>completions / min_length</th>\n",
              "      <th>completions / max_length</th>\n",
              "      <th>completions / clipped_ratio</th>\n",
              "      <th>completions / mean_terminated_length</th>\n",
              "      <th>completions / min_terminated_length</th>\n",
              "      <th>completions / max_terminated_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / numbering_reward_func / mean</th>\n",
              "      <th>rewards / numbering_reward_func / std</th>\n",
              "      <th>rewards / spelling_reward_func / mean</th>\n",
              "      <th>rewards / spelling_reward_func / std</th>\n",
              "      <th>rewards / counting_reward_func / mean</th>\n",
              "      <th>rewards / counting_reward_func / std</th>\n",
              "      <th>rewards / format_reward_func / mean</th>\n",
              "      <th>rewards / format_reward_func / std</th>\n",
              "      <th>rewards / correct_answer_reward_func / mean</th>\n",
              "      <th>rewards / correct_answer_reward_func / std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>1.840551</td>\n",
              "      <td>2.349435</td>\n",
              "      <td>92.562500</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>156.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>92.562500</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>156.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.362723</td>\n",
              "      <td>0.154479</td>\n",
              "      <td>-1.156250</td>\n",
              "      <td>2.248842</td>\n",
              "      <td>0.009077</td>\n",
              "      <td>0.769412</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>1.629514</td>\n",
              "      <td>1.839450</td>\n",
              "      <td>79.437500</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.437500</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.453125</td>\n",
              "      <td>0.053522</td>\n",
              "      <td>-0.656250</td>\n",
              "      <td>2.930977</td>\n",
              "      <td>-0.042361</td>\n",
              "      <td>0.620331</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>1.388765</td>\n",
              "      <td>2.575400</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.406622</td>\n",
              "      <td>0.118764</td>\n",
              "      <td>-1.125000</td>\n",
              "      <td>2.753785</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>0.583795</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.549193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>1.238988</td>\n",
              "      <td>1.886621</td>\n",
              "      <td>79.375000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.375000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.458333</td>\n",
              "      <td>0.060858</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>1.955495</td>\n",
              "      <td>-0.313095</td>\n",
              "      <td>0.681006</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.062500</td>\n",
              "      <td>1.436141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>2.231101</td>\n",
              "      <td>2.185562</td>\n",
              "      <td>80.437500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80.437500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.429018</td>\n",
              "      <td>0.137283</td>\n",
              "      <td>-0.093750</td>\n",
              "      <td>2.192554</td>\n",
              "      <td>0.020833</td>\n",
              "      <td>0.647509</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of e's in the word sapphire\n",
            "1. s - 0 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "4. a - 2 so far\n",
            "5. r - 2 so far\n",
            "6. p - 3 so far\n",
            "7. h - 3 so far\n",
            "8. a - 4 so far\n",
            "9. y - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"x\" are there in the word \"absolve\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of x's in the word absolve\n",
            "1. a - 0 so far\n",
            "2. b - 1 so far\n",
            "3. s - 2 so far\n",
            "4. x - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"mirage\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word \"mirage\"\n",
            "1. m - 0 so far\n",
            "2. i - 0 so far\n",
            "3. r - 0 so far\n",
            "4. a - 0 so far\n",
            "5. g - 1 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"crave\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word crave\n",
            "1. c - 0 so far\n",
            "2. r - 1 so far\n",
            "3. a - 1 so far\n",
            "4. v - 1 so far\n",
            "5. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "time: 5min 10s (started: 2025-12-22 19:09:53 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Train for just a few steps for a few minutes\n",
        "# This will allow us to observe the results and make any changes to our reward functions\n",
        "# before starting a longer run. Note, you won't see much change in the average.\n",
        "# reward values\n",
        "# No changes are needed here\n",
        "\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "from unsloth import PatchFastRL\n",
        "PatchFastRL(\"GRPO\", FastLanguageModel)\n",
        "\n",
        "# 1. Create the corrected dictionary\n",
        "grpo_params = COMMON_GRPO_TRAINING_PARAMS.copy()\n",
        "grpo_params[\"use_vllm\"] = False\n",
        "\n",
        "# 2. Use the corrected dictionary here!\n",
        "training_args = GRPOConfig(\n",
        "    **grpo_params,  # Use grpo_params, NOT COMMON_GRPO_TRAINING_PARAMS\n",
        "    max_steps = 5,\n",
        ")\n",
        "\n",
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    processing_class=tokenizer,\n",
        "    reward_funcs=REWARD_FUNCS,\n",
        "    args=training_args,\n",
        "    train_dataset=ds,\n",
        ")\n",
        "trainer_res = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p95xpKvrHfBa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "collapsed": true,
        "outputId": "7bc0fbde-6936-4a0b-c432-a109a25c5520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "available columns: dict_keys(['loss', 'grad_norm', 'learning_rate', 'num_tokens', 'completions/mean_length', 'completions/min_length', 'completions/max_length', 'completions/clipped_ratio', 'completions/mean_terminated_length', 'completions/min_terminated_length', 'completions/max_terminated_length', 'rewards/numbering_reward_func/mean', 'rewards/numbering_reward_func/std', 'rewards/spelling_reward_func/mean', 'rewards/spelling_reward_func/std', 'rewards/counting_reward_func/mean', 'rewards/counting_reward_func/std', 'rewards/format_reward_func/mean', 'rewards/format_reward_func/std', 'rewards/correct_answer_reward_func/mean', 'rewards/correct_answer_reward_func/std', 'reward', 'reward_std', 'frac_reward_zero_std', 'completion_length', 'kl', 'epoch', 'step'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 345 ms (started: 2025-12-22 19:15:04 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Show the total (sum) of the rewards as well as the correct_answer_reward_func (means with in the batch)\n",
        "# No changes needed in this cell\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# If you want to graph other columns, check these out\n",
        "print(f\"available columns: {trainer.state.log_history[0].keys()}\")\n",
        "\n",
        "log_df = pd.DataFrame(trainer.state.log_history)\n",
        "log_df[\"reward\"].plot()\n",
        "log_df[\"rewards/correct_answer_reward_func/mean\"].plot()\n",
        "\n",
        "# Show the legend\n",
        "plt.legend([\"reward\", \"rewards/correct_answer_reward_func/mean\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YZJD6Q8HfBa"
      },
      "source": [
        "### Slower train (1+ hour)\n",
        "\n",
        "If everything looks good, let's go for a longer training session!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_APkyUnHfBa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d2663b88-9f98-4e57-d241-3cb3a0c958aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 401 | Num Epochs = 1 | Total steps = 75\n",
            "O^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 1\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 1 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 119,734,272 of 3,205,672,960 (3.74% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"glisten\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word glisten\n",
            "1. g - 1 so far\n",
            "2. l - 1 so far\n",
            "3. i - 1 so far\n",
            "4. s - 1 so far\n",
            "5. t - 1 so far\n",
            "6. e - 1 so far\n",
            "7. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [75/75 34:34, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completions / mean_length</th>\n",
              "      <th>completions / min_length</th>\n",
              "      <th>completions / max_length</th>\n",
              "      <th>completions / clipped_ratio</th>\n",
              "      <th>completions / mean_terminated_length</th>\n",
              "      <th>completions / min_terminated_length</th>\n",
              "      <th>completions / max_terminated_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / numbering_reward_func / mean</th>\n",
              "      <th>rewards / numbering_reward_func / std</th>\n",
              "      <th>rewards / spelling_reward_func / mean</th>\n",
              "      <th>rewards / spelling_reward_func / std</th>\n",
              "      <th>rewards / counting_reward_func / mean</th>\n",
              "      <th>rewards / counting_reward_func / std</th>\n",
              "      <th>rewards / format_reward_func / mean</th>\n",
              "      <th>rewards / format_reward_func / std</th>\n",
              "      <th>rewards / correct_answer_reward_func / mean</th>\n",
              "      <th>rewards / correct_answer_reward_func / std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.856473</td>\n",
              "      <td>2.412027</td>\n",
              "      <td>91.125000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>91.125000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>0.002850</td>\n",
              "      <td>0.373884</td>\n",
              "      <td>0.145223</td>\n",
              "      <td>-0.843750</td>\n",
              "      <td>2.256241</td>\n",
              "      <td>0.076339</td>\n",
              "      <td>0.760638</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.177431</td>\n",
              "      <td>2.434868</td>\n",
              "      <td>93.687500</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>196.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.687500</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>196.000000</td>\n",
              "      <td>0.003972</td>\n",
              "      <td>0.440625</td>\n",
              "      <td>0.052738</td>\n",
              "      <td>-1.593750</td>\n",
              "      <td>3.023347</td>\n",
              "      <td>0.018056</td>\n",
              "      <td>0.608160</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.630060</td>\n",
              "      <td>2.630259</td>\n",
              "      <td>86.687500</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.687500</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>0.003895</td>\n",
              "      <td>0.422619</td>\n",
              "      <td>0.101552</td>\n",
              "      <td>-1.406250</td>\n",
              "      <td>2.245134</td>\n",
              "      <td>0.301190</td>\n",
              "      <td>0.664970</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.401339</td>\n",
              "      <td>1.663686</td>\n",
              "      <td>80.625000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80.625000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.002672</td>\n",
              "      <td>0.463542</td>\n",
              "      <td>0.042696</td>\n",
              "      <td>-0.093750</td>\n",
              "      <td>1.908042</td>\n",
              "      <td>-0.280952</td>\n",
              "      <td>0.500715</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.770461</td>\n",
              "      <td>1.737792</td>\n",
              "      <td>78.125000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>78.125000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.002599</td>\n",
              "      <td>0.447545</td>\n",
              "      <td>0.133546</td>\n",
              "      <td>-0.031250</td>\n",
              "      <td>2.117142</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.625236</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.189435</td>\n",
              "      <td>1.327118</td>\n",
              "      <td>72.062500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>72.062500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>0.003727</td>\n",
              "      <td>0.411161</td>\n",
              "      <td>0.136644</td>\n",
              "      <td>-0.750000</td>\n",
              "      <td>2.190890</td>\n",
              "      <td>0.215774</td>\n",
              "      <td>0.718215</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.098958</td>\n",
              "      <td>2.164848</td>\n",
              "      <td>74.562500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>74.562500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>0.004085</td>\n",
              "      <td>0.359375</td>\n",
              "      <td>0.088659</td>\n",
              "      <td>-1.875000</td>\n",
              "      <td>1.347838</td>\n",
              "      <td>0.302083</td>\n",
              "      <td>0.553971</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070933</td>\n",
              "      <td>0.817885</td>\n",
              "      <td>87.562500</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.562500</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.002724</td>\n",
              "      <td>0.433036</td>\n",
              "      <td>0.062969</td>\n",
              "      <td>-1.500000</td>\n",
              "      <td>1.414214</td>\n",
              "      <td>0.200397</td>\n",
              "      <td>0.769710</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.062500</td>\n",
              "      <td>1.436141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.342560</td>\n",
              "      <td>2.648365</td>\n",
              "      <td>76.375000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>76.375000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>0.003837</td>\n",
              "      <td>0.324405</td>\n",
              "      <td>0.170686</td>\n",
              "      <td>-2.125000</td>\n",
              "      <td>2.202272</td>\n",
              "      <td>0.145536</td>\n",
              "      <td>0.788193</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.334747</td>\n",
              "      <td>2.203437</td>\n",
              "      <td>77.937500</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>77.937500</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.002887</td>\n",
              "      <td>0.445759</td>\n",
              "      <td>0.058455</td>\n",
              "      <td>-0.312500</td>\n",
              "      <td>1.931105</td>\n",
              "      <td>-0.111012</td>\n",
              "      <td>0.487100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.659970</td>\n",
              "      <td>1.304292</td>\n",
              "      <td>84.437500</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84.437500</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>0.009858</td>\n",
              "      <td>0.362500</td>\n",
              "      <td>0.087346</td>\n",
              "      <td>-2.562500</td>\n",
              "      <td>1.833712</td>\n",
              "      <td>0.227530</td>\n",
              "      <td>0.622250</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.122724</td>\n",
              "      <td>1.003909</td>\n",
              "      <td>83.500000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>154.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>83.500000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>154.000000</td>\n",
              "      <td>0.008505</td>\n",
              "      <td>0.397656</td>\n",
              "      <td>0.109184</td>\n",
              "      <td>-2.406250</td>\n",
              "      <td>2.083417</td>\n",
              "      <td>0.256318</td>\n",
              "      <td>0.787377</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.811086</td>\n",
              "      <td>1.139465</td>\n",
              "      <td>74.750000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>74.750000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.442336</td>\n",
              "      <td>0.097583</td>\n",
              "      <td>-1.531250</td>\n",
              "      <td>2.362688</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.457347</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.062500</td>\n",
              "      <td>1.436141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.423760</td>\n",
              "      <td>2.528434</td>\n",
              "      <td>83.375000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>83.375000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>0.005496</td>\n",
              "      <td>0.414732</td>\n",
              "      <td>0.122592</td>\n",
              "      <td>-0.687500</td>\n",
              "      <td>2.189939</td>\n",
              "      <td>0.009028</td>\n",
              "      <td>0.630342</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.322768</td>\n",
              "      <td>1.743258</td>\n",
              "      <td>62.312500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>62.312500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>0.006823</td>\n",
              "      <td>0.359375</td>\n",
              "      <td>0.164792</td>\n",
              "      <td>-0.468750</td>\n",
              "      <td>2.202035</td>\n",
              "      <td>0.807143</td>\n",
              "      <td>0.408282</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.488542</td>\n",
              "      <td>2.935004</td>\n",
              "      <td>98.625000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>91.866669</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>186.000000</td>\n",
              "      <td>0.005681</td>\n",
              "      <td>0.440625</td>\n",
              "      <td>0.090670</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>2.932576</td>\n",
              "      <td>0.297917</td>\n",
              "      <td>0.683878</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.462644</td>\n",
              "      <td>2.033242</td>\n",
              "      <td>92.187500</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>92.187500</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.007332</td>\n",
              "      <td>0.378720</td>\n",
              "      <td>0.082334</td>\n",
              "      <td>-2.781250</td>\n",
              "      <td>1.897092</td>\n",
              "      <td>-0.435115</td>\n",
              "      <td>0.552500</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.625000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>1.698532</td>\n",
              "      <td>88.687500</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>88.687500</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>0.007515</td>\n",
              "      <td>0.479167</td>\n",
              "      <td>0.037268</td>\n",
              "      <td>-1.062500</td>\n",
              "      <td>2.056494</td>\n",
              "      <td>-0.005952</td>\n",
              "      <td>0.683213</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.458631</td>\n",
              "      <td>1.159549</td>\n",
              "      <td>88.187500</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>88.187500</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>0.013500</td>\n",
              "      <td>0.434821</td>\n",
              "      <td>0.086499</td>\n",
              "      <td>-1.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.106548</td>\n",
              "      <td>0.724538</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>1.468683</td>\n",
              "      <td>91.562500</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>84.333336</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0.009763</td>\n",
              "      <td>0.417411</td>\n",
              "      <td>0.057329</td>\n",
              "      <td>-1.468750</td>\n",
              "      <td>0.718070</td>\n",
              "      <td>0.270089</td>\n",
              "      <td>0.576019</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.669940</td>\n",
              "      <td>1.249721</td>\n",
              "      <td>85.687500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.687500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0.012968</td>\n",
              "      <td>0.433036</td>\n",
              "      <td>0.096287</td>\n",
              "      <td>-1.968750</td>\n",
              "      <td>0.956883</td>\n",
              "      <td>0.115774</td>\n",
              "      <td>0.712174</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.672247</td>\n",
              "      <td>1.621728</td>\n",
              "      <td>94.250000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>157.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.250000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>157.000000</td>\n",
              "      <td>0.018772</td>\n",
              "      <td>0.446057</td>\n",
              "      <td>0.060017</td>\n",
              "      <td>-1.062500</td>\n",
              "      <td>2.104558</td>\n",
              "      <td>-0.211310</td>\n",
              "      <td>0.770837</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.549193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.490327</td>\n",
              "      <td>2.591907</td>\n",
              "      <td>85.125000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.125000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>0.015287</td>\n",
              "      <td>0.427083</td>\n",
              "      <td>0.113346</td>\n",
              "      <td>-0.750000</td>\n",
              "      <td>2.442676</td>\n",
              "      <td>0.313244</td>\n",
              "      <td>0.636027</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.549193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.932217</td>\n",
              "      <td>1.763584</td>\n",
              "      <td>103.062500</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>138.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>103.062500</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>138.000000</td>\n",
              "      <td>0.013341</td>\n",
              "      <td>0.411979</td>\n",
              "      <td>0.084367</td>\n",
              "      <td>-3.468750</td>\n",
              "      <td>1.309819</td>\n",
              "      <td>-0.375446</td>\n",
              "      <td>0.381964</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.549193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.411508</td>\n",
              "      <td>1.773231</td>\n",
              "      <td>86.250000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.250000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>0.011418</td>\n",
              "      <td>0.427083</td>\n",
              "      <td>0.112425</td>\n",
              "      <td>-1.687500</td>\n",
              "      <td>2.897557</td>\n",
              "      <td>0.359425</td>\n",
              "      <td>0.649138</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.993452</td>\n",
              "      <td>1.832316</td>\n",
              "      <td>93.500000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>171.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.500000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>171.000000</td>\n",
              "      <td>0.011967</td>\n",
              "      <td>0.352679</td>\n",
              "      <td>0.223559</td>\n",
              "      <td>-2.406250</td>\n",
              "      <td>1.572882</td>\n",
              "      <td>0.122619</td>\n",
              "      <td>0.732356</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.062500</td>\n",
              "      <td>1.436141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.349653</td>\n",
              "      <td>1.787870</td>\n",
              "      <td>89.437500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>165.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>89.437500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>165.000000</td>\n",
              "      <td>0.012783</td>\n",
              "      <td>0.408333</td>\n",
              "      <td>0.105126</td>\n",
              "      <td>-1.375000</td>\n",
              "      <td>2.179450</td>\n",
              "      <td>-0.183681</td>\n",
              "      <td>0.609796</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.549193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.219048</td>\n",
              "      <td>2.018846</td>\n",
              "      <td>87.437500</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.437500</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>0.017821</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.125831</td>\n",
              "      <td>-0.343750</td>\n",
              "      <td>2.126960</td>\n",
              "      <td>0.250298</td>\n",
              "      <td>0.779181</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.005258</td>\n",
              "      <td>1.428254</td>\n",
              "      <td>72.750000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>72.750000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>0.022977</td>\n",
              "      <td>0.354167</td>\n",
              "      <td>0.173472</td>\n",
              "      <td>-2.656250</td>\n",
              "      <td>2.605883</td>\n",
              "      <td>0.171825</td>\n",
              "      <td>0.754716</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.784821</td>\n",
              "      <td>1.905788</td>\n",
              "      <td>62.625000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>62.625000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>0.028318</td>\n",
              "      <td>0.366071</td>\n",
              "      <td>0.131223</td>\n",
              "      <td>-1.187500</td>\n",
              "      <td>2.365551</td>\n",
              "      <td>-0.456250</td>\n",
              "      <td>0.460550</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.062500</td>\n",
              "      <td>1.436141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.569196</td>\n",
              "      <td>1.428424</td>\n",
              "      <td>89.562500</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>89.562500</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>0.018706</td>\n",
              "      <td>0.377232</td>\n",
              "      <td>0.087343</td>\n",
              "      <td>-2.406250</td>\n",
              "      <td>1.428504</td>\n",
              "      <td>-0.102679</td>\n",
              "      <td>0.638253</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.437500</td>\n",
              "      <td>1.209339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.239831</td>\n",
              "      <td>2.183157</td>\n",
              "      <td>82.062500</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.062500</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>0.024543</td>\n",
              "      <td>0.412946</td>\n",
              "      <td>0.086227</td>\n",
              "      <td>-1.375000</td>\n",
              "      <td>2.179450</td>\n",
              "      <td>-0.215278</td>\n",
              "      <td>0.634896</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.062500</td>\n",
              "      <td>1.436141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.210280</td>\n",
              "      <td>3.054051</td>\n",
              "      <td>75.812500</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>75.812500</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.029181</td>\n",
              "      <td>0.433594</td>\n",
              "      <td>0.086809</td>\n",
              "      <td>-0.750000</td>\n",
              "      <td>2.774887</td>\n",
              "      <td>0.026687</td>\n",
              "      <td>0.565063</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.549193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.216922</td>\n",
              "      <td>2.361811</td>\n",
              "      <td>89.062500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>89.062500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>0.020845</td>\n",
              "      <td>0.439509</td>\n",
              "      <td>0.079341</td>\n",
              "      <td>-1.031250</td>\n",
              "      <td>2.472979</td>\n",
              "      <td>-0.066337</td>\n",
              "      <td>0.526834</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.073140</td>\n",
              "      <td>2.108856</td>\n",
              "      <td>72.750000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>72.750000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>0.027991</td>\n",
              "      <td>0.407813</td>\n",
              "      <td>0.083526</td>\n",
              "      <td>-1.250000</td>\n",
              "      <td>1.471960</td>\n",
              "      <td>0.019048</td>\n",
              "      <td>0.593367</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.056845</td>\n",
              "      <td>2.669566</td>\n",
              "      <td>74.687500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>148.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>74.687500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>148.000000</td>\n",
              "      <td>0.019092</td>\n",
              "      <td>0.385417</td>\n",
              "      <td>0.160655</td>\n",
              "      <td>-1.468750</td>\n",
              "      <td>3.298832</td>\n",
              "      <td>0.077679</td>\n",
              "      <td>0.592576</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.062500</td>\n",
              "      <td>1.436141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.966964</td>\n",
              "      <td>1.317146</td>\n",
              "      <td>87.812500</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.812500</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.027291</td>\n",
              "      <td>0.439732</td>\n",
              "      <td>0.076605</td>\n",
              "      <td>-0.437500</td>\n",
              "      <td>1.833712</td>\n",
              "      <td>0.089732</td>\n",
              "      <td>0.805007</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.076525</td>\n",
              "      <td>1.108201</td>\n",
              "      <td>94.312500</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.312500</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>0.033008</td>\n",
              "      <td>0.446987</td>\n",
              "      <td>0.039681</td>\n",
              "      <td>-1.968750</td>\n",
              "      <td>2.452677</td>\n",
              "      <td>-0.117262</td>\n",
              "      <td>0.622304</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.437500</td>\n",
              "      <td>1.209339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.559474</td>\n",
              "      <td>2.623549</td>\n",
              "      <td>85.375000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.375000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.036908</td>\n",
              "      <td>0.429315</td>\n",
              "      <td>0.076718</td>\n",
              "      <td>-0.562500</td>\n",
              "      <td>2.542145</td>\n",
              "      <td>-0.057341</td>\n",
              "      <td>0.623199</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.285565</td>\n",
              "      <td>1.804305</td>\n",
              "      <td>97.187500</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>97.187500</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>0.025578</td>\n",
              "      <td>0.367708</td>\n",
              "      <td>0.194800</td>\n",
              "      <td>-2.125000</td>\n",
              "      <td>1.132843</td>\n",
              "      <td>0.346726</td>\n",
              "      <td>0.731019</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.210119</td>\n",
              "      <td>1.577993</td>\n",
              "      <td>81.625000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.625000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.051445</td>\n",
              "      <td>0.452976</td>\n",
              "      <td>0.051069</td>\n",
              "      <td>-0.437500</td>\n",
              "      <td>1.611159</td>\n",
              "      <td>0.132143</td>\n",
              "      <td>0.450492</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.062500</td>\n",
              "      <td>1.436141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.861235</td>\n",
              "      <td>2.378855</td>\n",
              "      <td>78.125000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>78.125000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>0.040012</td>\n",
              "      <td>0.376563</td>\n",
              "      <td>0.084723</td>\n",
              "      <td>-2.125000</td>\n",
              "      <td>1.477611</td>\n",
              "      <td>0.137202</td>\n",
              "      <td>0.620826</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.400223</td>\n",
              "      <td>1.597752</td>\n",
              "      <td>86.812500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.812500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>0.032318</td>\n",
              "      <td>0.335938</td>\n",
              "      <td>0.174351</td>\n",
              "      <td>-3.156250</td>\n",
              "      <td>2.030753</td>\n",
              "      <td>-0.142411</td>\n",
              "      <td>0.746824</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.437500</td>\n",
              "      <td>1.209339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.933854</td>\n",
              "      <td>2.705465</td>\n",
              "      <td>89.875000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>89.875000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>0.025203</td>\n",
              "      <td>0.445312</td>\n",
              "      <td>0.099441</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>2.280351</td>\n",
              "      <td>0.238542</td>\n",
              "      <td>0.552986</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.549193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.403534</td>\n",
              "      <td>1.782923</td>\n",
              "      <td>87.125000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.125000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>0.037931</td>\n",
              "      <td>0.451451</td>\n",
              "      <td>0.103457</td>\n",
              "      <td>-0.906250</td>\n",
              "      <td>3.747082</td>\n",
              "      <td>-0.079167</td>\n",
              "      <td>0.601813</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.062500</td>\n",
              "      <td>1.436141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.121578</td>\n",
              "      <td>2.470716</td>\n",
              "      <td>78.375000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>78.375000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.047868</td>\n",
              "      <td>0.429911</td>\n",
              "      <td>0.059925</td>\n",
              "      <td>-0.750000</td>\n",
              "      <td>1.712698</td>\n",
              "      <td>0.191667</td>\n",
              "      <td>0.600185</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.550893</td>\n",
              "      <td>2.924666</td>\n",
              "      <td>72.875000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>72.875000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.079207</td>\n",
              "      <td>0.425298</td>\n",
              "      <td>0.110936</td>\n",
              "      <td>-1.156250</td>\n",
              "      <td>2.637668</td>\n",
              "      <td>0.156845</td>\n",
              "      <td>0.684606</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.022470</td>\n",
              "      <td>1.967734</td>\n",
              "      <td>82.937500</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.937500</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.054674</td>\n",
              "      <td>0.467708</td>\n",
              "      <td>0.052869</td>\n",
              "      <td>-0.187500</td>\n",
              "      <td>1.913766</td>\n",
              "      <td>0.242262</td>\n",
              "      <td>0.606081</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.549193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.539583</td>\n",
              "      <td>2.065670</td>\n",
              "      <td>79.062500</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.062500</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>0.050744</td>\n",
              "      <td>0.452083</td>\n",
              "      <td>0.086039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.476557</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>0.580932</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.062500</td>\n",
              "      <td>1.436141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.050149</td>\n",
              "      <td>2.163570</td>\n",
              "      <td>79.562500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.562500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.064179</td>\n",
              "      <td>0.392262</td>\n",
              "      <td>0.132915</td>\n",
              "      <td>-2.250000</td>\n",
              "      <td>2.435843</td>\n",
              "      <td>0.407887</td>\n",
              "      <td>0.783008</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.549193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.450645</td>\n",
              "      <td>2.543707</td>\n",
              "      <td>93.125000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.125000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.055667</td>\n",
              "      <td>0.433631</td>\n",
              "      <td>0.052918</td>\n",
              "      <td>-1.875000</td>\n",
              "      <td>1.830301</td>\n",
              "      <td>-0.134276</td>\n",
              "      <td>0.530723</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.435305</td>\n",
              "      <td>2.558130</td>\n",
              "      <td>90.437500</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90.437500</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>0.072622</td>\n",
              "      <td>0.455915</td>\n",
              "      <td>0.071439</td>\n",
              "      <td>-1.687500</td>\n",
              "      <td>2.581182</td>\n",
              "      <td>-0.141220</td>\n",
              "      <td>0.624731</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.062500</td>\n",
              "      <td>1.436141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.364286</td>\n",
              "      <td>0.880839</td>\n",
              "      <td>69.687500</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69.687500</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.071089</td>\n",
              "      <td>0.433333</td>\n",
              "      <td>0.065969</td>\n",
              "      <td>-0.625000</td>\n",
              "      <td>1.755942</td>\n",
              "      <td>0.180952</td>\n",
              "      <td>0.643002</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.625000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.265972</td>\n",
              "      <td>2.218018</td>\n",
              "      <td>81.375000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.375000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.048346</td>\n",
              "      <td>0.378720</td>\n",
              "      <td>0.128458</td>\n",
              "      <td>-2.062500</td>\n",
              "      <td>1.436141</td>\n",
              "      <td>-0.082192</td>\n",
              "      <td>0.749500</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.549193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.605803</td>\n",
              "      <td>1.508078</td>\n",
              "      <td>87.250000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.250000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>0.044504</td>\n",
              "      <td>0.383036</td>\n",
              "      <td>0.135289</td>\n",
              "      <td>-0.937500</td>\n",
              "      <td>2.112463</td>\n",
              "      <td>-0.089732</td>\n",
              "      <td>0.613133</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.400149</td>\n",
              "      <td>0.725902</td>\n",
              "      <td>77.125000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>77.125000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.058935</td>\n",
              "      <td>0.351042</td>\n",
              "      <td>0.130024</td>\n",
              "      <td>-2.281250</td>\n",
              "      <td>1.032291</td>\n",
              "      <td>0.455357</td>\n",
              "      <td>0.627890</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.733333</td>\n",
              "      <td>2.321703</td>\n",
              "      <td>78.625000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>78.625000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>0.047746</td>\n",
              "      <td>0.449107</td>\n",
              "      <td>0.104585</td>\n",
              "      <td>0.218750</td>\n",
              "      <td>2.280123</td>\n",
              "      <td>-0.247024</td>\n",
              "      <td>0.566534</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.814475</td>\n",
              "      <td>2.027195</td>\n",
              "      <td>90.812500</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90.812500</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.051618</td>\n",
              "      <td>0.444643</td>\n",
              "      <td>0.081127</td>\n",
              "      <td>-0.656250</td>\n",
              "      <td>2.488097</td>\n",
              "      <td>-0.098918</td>\n",
              "      <td>0.678835</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.405804</td>\n",
              "      <td>1.505028</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.050817</td>\n",
              "      <td>0.445982</td>\n",
              "      <td>0.099817</td>\n",
              "      <td>-0.156250</td>\n",
              "      <td>1.786232</td>\n",
              "      <td>0.491071</td>\n",
              "      <td>0.625357</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.448512</td>\n",
              "      <td>1.389361</td>\n",
              "      <td>73.375000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>73.375000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.069034</td>\n",
              "      <td>0.439137</td>\n",
              "      <td>0.075483</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.152518</td>\n",
              "      <td>0.009375</td>\n",
              "      <td>0.595393</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.737649</td>\n",
              "      <td>3.712664</td>\n",
              "      <td>81.937500</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>157.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.937500</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>157.000000</td>\n",
              "      <td>0.044008</td>\n",
              "      <td>0.408185</td>\n",
              "      <td>0.301292</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>2.886571</td>\n",
              "      <td>0.360714</td>\n",
              "      <td>0.556054</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.341641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.477530</td>\n",
              "      <td>2.067991</td>\n",
              "      <td>81.500000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.500000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>0.052712</td>\n",
              "      <td>0.408929</td>\n",
              "      <td>0.100815</td>\n",
              "      <td>-2.531250</td>\n",
              "      <td>1.117568</td>\n",
              "      <td>-0.230208</td>\n",
              "      <td>0.678539</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.401414</td>\n",
              "      <td>2.553535</td>\n",
              "      <td>88.625000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>88.625000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>0.062958</td>\n",
              "      <td>0.386830</td>\n",
              "      <td>0.113490</td>\n",
              "      <td>-1.406250</td>\n",
              "      <td>1.529910</td>\n",
              "      <td>0.108333</td>\n",
              "      <td>0.786036</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.005208</td>\n",
              "      <td>2.899551</td>\n",
              "      <td>99.687500</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>99.687500</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>0.043958</td>\n",
              "      <td>0.406250</td>\n",
              "      <td>0.067746</td>\n",
              "      <td>-3.156250</td>\n",
              "      <td>1.841365</td>\n",
              "      <td>-0.380208</td>\n",
              "      <td>0.594363</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.515557</td>\n",
              "      <td>0.866801</td>\n",
              "      <td>78.750000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>78.750000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.079634</td>\n",
              "      <td>0.397321</td>\n",
              "      <td>0.145145</td>\n",
              "      <td>-2.156250</td>\n",
              "      <td>2.095382</td>\n",
              "      <td>0.118371</td>\n",
              "      <td>0.719682</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.773958</td>\n",
              "      <td>0.924237</td>\n",
              "      <td>69.937500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69.937500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.067698</td>\n",
              "      <td>0.438542</td>\n",
              "      <td>0.120142</td>\n",
              "      <td>-0.375000</td>\n",
              "      <td>2.037155</td>\n",
              "      <td>0.022917</td>\n",
              "      <td>0.613154</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.094643</td>\n",
              "      <td>2.232470</td>\n",
              "      <td>81.750000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.750000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.054653</td>\n",
              "      <td>0.391071</td>\n",
              "      <td>0.146141</td>\n",
              "      <td>-1.312500</td>\n",
              "      <td>2.522400</td>\n",
              "      <td>0.328571</td>\n",
              "      <td>0.764235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.266369</td>\n",
              "      <td>1.793893</td>\n",
              "      <td>81.375000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.375000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.062840</td>\n",
              "      <td>0.447917</td>\n",
              "      <td>0.067185</td>\n",
              "      <td>-0.875000</td>\n",
              "      <td>1.678293</td>\n",
              "      <td>0.005952</td>\n",
              "      <td>0.586282</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.028199</td>\n",
              "      <td>2.249881</td>\n",
              "      <td>74.562500</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>74.562500</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>0.058103</td>\n",
              "      <td>0.417188</td>\n",
              "      <td>0.068750</td>\n",
              "      <td>-0.593750</td>\n",
              "      <td>1.645385</td>\n",
              "      <td>0.579762</td>\n",
              "      <td>0.446732</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.404613</td>\n",
              "      <td>1.975194</td>\n",
              "      <td>73.687500</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>73.687500</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.052172</td>\n",
              "      <td>0.392857</td>\n",
              "      <td>0.123086</td>\n",
              "      <td>-1.468750</td>\n",
              "      <td>2.383756</td>\n",
              "      <td>-0.266220</td>\n",
              "      <td>0.455752</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.062500</td>\n",
              "      <td>1.436141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.701935</td>\n",
              "      <td>2.696316</td>\n",
              "      <td>79.437500</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.437500</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>0.062447</td>\n",
              "      <td>0.441220</td>\n",
              "      <td>0.068762</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>1.966384</td>\n",
              "      <td>0.135714</td>\n",
              "      <td>0.548660</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.614062</td>\n",
              "      <td>0.906202</td>\n",
              "      <td>69.062500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69.062500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.062185</td>\n",
              "      <td>0.418527</td>\n",
              "      <td>0.102885</td>\n",
              "      <td>-1.187500</td>\n",
              "      <td>1.998958</td>\n",
              "      <td>-0.116964</td>\n",
              "      <td>0.533831</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.549193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.778993</td>\n",
              "      <td>0.943363</td>\n",
              "      <td>83.125000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>134.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>83.125000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>134.000000</td>\n",
              "      <td>0.052135</td>\n",
              "      <td>0.476562</td>\n",
              "      <td>0.044925</td>\n",
              "      <td>-0.312500</td>\n",
              "      <td>3.365883</td>\n",
              "      <td>0.302431</td>\n",
              "      <td>0.572709</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.537043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.433036</td>\n",
              "      <td>1.947714</td>\n",
              "      <td>78.437500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>78.437500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.052724</td>\n",
              "      <td>0.383929</td>\n",
              "      <td>0.141924</td>\n",
              "      <td>-2.406250</td>\n",
              "      <td>1.714825</td>\n",
              "      <td>0.089286</td>\n",
              "      <td>0.766103</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.549193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.412351</td>\n",
              "      <td>1.169582</td>\n",
              "      <td>64.750000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>64.750000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>0.068935</td>\n",
              "      <td>0.372768</td>\n",
              "      <td>0.070190</td>\n",
              "      <td>-1.343750</td>\n",
              "      <td>0.507239</td>\n",
              "      <td>0.320833</td>\n",
              "      <td>0.496040</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.062500</td>\n",
              "      <td>1.436141</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of e's in the word sapphire\n",
            "1. s - 0 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "4. a - 2 so far\n",
            "5. f - 2 so far\n",
            "6. l - 2 so far\n",
            "7. a - 3 so far\n",
            "8. y - 3 so far\n",
            "9. e - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"x\" are there in the word \"absolve\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of x's in the word abslove\n",
            "1. a - 0 so far\n",
            "2. b - 1 so far\n",
            "3. s - 1 so far\n",
            "4. x - 1 so far\n",
            "5. v - 2 so far\n",
            "6. e - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"mirage\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word \"mirage\"\n",
            "1. m - 0 so far\n",
            "2. i - 0 so far\n",
            "3. r - 0 so far\n",
            "4. a - 0 so far\n",
            "5. g - 1 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"crave\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word crave\n",
            "1. c - 0 so far\n",
            "2. r - 1 so far\n",
            "3. a - 1 so far\n",
            "4. v - 1 so far\n",
            "5. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"u\" are there in the word \"frescos\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of u's in the word frescos\n",
            "1. f - 0 so far\n",
            "2. r - 1 so far\n",
            "3. e - 2 so far\n",
            "4. s - 3 so far\n",
            "5. c - 4 so far\n",
            "6. o - 5 so far\n",
            "7. u - 6 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"v\" are there in the word \"absolve\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of v's in the word \"absolve\"\n",
            "1. a - 1 so far\n",
            "2. b - 0 so far\n",
            "3. s - 0 so far\n",
            "4. s - 1 so far\n",
            "5. v - 1 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"eclipse\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"i\"s in the word \"eclipse\"\n",
            "1. e - 0 so far\n",
            "2. c - 0 so far\n",
            "3. l - 0 so far\n",
            "4. p - 0 so far\n",
            "5. l - 0 so far\n",
            "6. c - 0 so far\n",
            "7. e - 0 so far\n",
            "8. s - 0 so far\n",
            "9. e - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"echo\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of e's in the word echo\n",
            "1. e - 1 so far\n",
            "2. c - 0 so far\n",
            "3. h - 0 so far\n",
            "4. o - 0 so far\n",
            "5. c - 0 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"d\" are there in the word \"void\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of d's in the word void\n",
            "1. v - 0 so far\n",
            "2. o - 1 so far\n",
            "3. i - 2 so far\n",
            "4. v - 3 so far\n",
            "5. d - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"o\" are there in the word \"ivory\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of o's in the word ivory\n",
            "1. i - 1 so far\n",
            "2. o - 0 so far\n",
            "3. r - 1 so far\n",
            "4. v - 1 so far\n",
            "5. y - 1 so far\n",
            "6. o - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"aperture\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. a - 1 so far\n",
            "2. p - 1 so far\n",
            "3. p - 1 (first occurrence) so far\n",
            "4. t - 0 so far\n",
            "5. e - 0 so far\n",
            "6. r - 0 so far\n",
            "7. a - 1 (a from previous step) so far\n",
            "8. p - 2 (second occurrence) so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"fume\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of m's in the word \"fume\"\n",
            "1. f - 0 so far\n",
            "2. m - 1 so far\n",
            "3. u - 1 so far\n",
            "4. m - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"crave\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. c - [count of requested letter so far] (there is 1 c) so far\n",
            "2. r - [count of requested letter so far] (no additional r's) so far\n",
            "3. a - [count of requested letter so far] (no additional a's) so far\n",
            "4. v - [count of requested letter so far] (no additional v's) so far\n",
            "5. e - [count of requested letter so far] (no additional e's) so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"f\" are there in the word \"frescos\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of f's in the word frescos\n",
            "1. f - 1 so far\n",
            "2. r - 0 (no other f's yet)\n",
            "3. e - 0 (no other f's yet)\n",
            "4. s - 1 (one f found)\n",
            "5. c - 0 (no other f's yet)\n",
            "6. o - 0 (no other f's yet)\n",
            "7. s - 0 (no other f's yet)\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"b\" are there in the word \"banner\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of b's in the word banner\n",
            "1. b - 1 so far\n",
            "2. a - 1 so far, adding 1 to the previous count (1+1=2)\n",
            "3. n - 1 so far, adding 1 to the previous count (2+1=3)\n",
            "4. a - 2 so far, adding 1 to the previous count (3+1=4)\n",
            "5. r - 3 so far, adding 1 to the previous count (4+1=5)\n",
            "6. a - 4 so far, adding 1 to the previous count (5+1=6)\n",
            "7. n - 5 so far, adding 1 to the previous count (6+1=7)\n",
            "8. a - 7 so far, adding 1 to the previous count (7+1=8)\n",
            "9. r - 8 so far, adding 1 to the\n",
            "Extracted: \n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"capture\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of n's in the word capture\n",
            "1. c - 0 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "4. u - 2 so far\n",
            "5. c - 3 so far\n",
            "6. a - 4 so far\n",
            "7. p - 5 so far\n",
            "8. e - 6 so far\n",
            "9. r - 7 so far\n",
            "10. a - 8 so far\n",
            "11. n - 9 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "9\n",
            "</answer>\n",
            "Extracted: 9\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"sphinx\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"p\" in the word \"sphinx\"\n",
            "1. s - 0 so far\n",
            "2. p - 1 so far\n",
            "3. n - 1 so far\n",
            "4. f - 1 so far\n",
            "5. p - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"k\" are there in the word \"knack\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of k's in the word \"knack\"\n",
            "1. k - 1 so far\n",
            "2. n - 1 still (no additional k's found)\n",
            "3. k - 2 so far\n",
            "4. c - 2 still (no additional k's found)\n",
            "5. k - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"relish\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word relish\n",
            "1. r - 1 so far\n",
            "2. e - 1 so far\n",
            "3. l - 1 so far\n",
            "4. i - 1 so far\n",
            "5. s - 1 so far\n",
            "6. h - 1 so far\n",
            "7. l - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"zealous\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of n's in the word \"zealous\"\n",
            "1. z - 1 so far\n",
            "2. e - 1 so far\n",
            "3. a - 1 so far\n",
            "4. l - 1 so far\n",
            "5. s - 1 so far\n",
            "6. o - 1 so far\n",
            "7. w - 1 so far\n",
            "8. e - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"q\" are there in the word \"idea\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of q's in the word idea\n",
            "1. i - 1 so far\n",
            "2. d - 1 so far\n",
            "3. e - 1 so far\n",
            "4. a - 1 so far\n",
            "5. q - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"tavern\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of t's in the word taurant\n",
            "1. t - 1 so far\n",
            "2. a - 1 so far\n",
            "3. u - 1 so far\n",
            "4. r - 1 so far\n",
            "5. a - 2 so far\n",
            "6. n - 2 so far\n",
            "7. t - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of s's in the word sapphire\n",
            "1. s - 1 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "4. a - 2 so far\n",
            "5. p - 3 so far\n",
            "6. h - 3 so far\n",
            "7. a - 4 so far\n",
            "8. y - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"a\"s in the word \"mantle\"\n",
            "1. m - 0 so far\n",
            "2. a - 1 so far\n",
            "3. n - 1 so far\n",
            "4. t - 1 so far\n",
            "5. l - 1 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"whistle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. w - 0 so far\n",
            "2. h - 0 so far\n",
            "3. w - 1 so far\n",
            "4. i - 1 so far\n",
            "5. s - 1 so far\n",
            "6. l - 1 so far\n",
            "7. t - 1 so far\n",
            "8. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"torrent\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of m's in the word \"torrent\"\n",
            "1. t - [count of requested letter so far] so far\n",
            "2. r - [count of requested letter so far] so far\n",
            "3. o - [count of requested letter so far] so far\n",
            "4. t - [count of requested letter so far] so far\n",
            "5. o - [count of requested letter so far] so far\n",
            "6. r - [count of requested letter so far] so far\n",
            "7. e - [count of requested letter so far] so far\n",
            "8. a - [count of requested letter so far] so far\n",
            "9. n - [count of requested letter so far] so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"w\" are there in the word \"brawn\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of w's in the word brawn\n",
            "1. b - 0 so far\n",
            "2. r - 0 so far\n",
            "3. w - 1 so far\n",
            "4. w - 1 (already counted) so far\n",
            "5. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"fathom\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. m - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"x\" are there in the word \"echo\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of x's in the word echo\n",
            "1. e - 1 so far\n",
            "2. c - 0 so far\n",
            "3. h - 0 so far\n",
            "4. o - 0 so far\n",
            "5. o - 1 so far\n",
            "6. x - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"enchant\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of n's in the word enchant\n",
            "1. e - 0 so far\n",
            "2. n - 1 so far\n",
            "3. a - 1 so far\n",
            "4. c - 1 so far\n",
            "5. h - 1 so far\n",
            "6. n - 2 so far\n",
            "7. t - 2 so far\n",
            "8. n - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"lush\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. l - 1 so far\n",
            "2. u - 0 so far\n",
            "3. s - 1 so far\n",
            "4. h - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"fusion\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. f - 1 so far\n",
            "2. u - 0 so far\n",
            "3. s - 1 so far\n",
            "4. i - 1 so far\n",
            "5. o - 0 so far\n",
            "6. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"b\" are there in the word \"maze\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of b's in the word \"maze\"\n",
            "1. m - 0 so far\n",
            "2. a - 1 so far\n",
            "3. z - 1 so far\n",
            "4. e - 2 so far\n",
            "There are no \"b\"s in the word \"maze\".\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"onset\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of t's in the word onset\n",
            "1. o - 0 so far\n",
            "2. n - 1 so far\n",
            "3. o - 1 so far\n",
            "4. s - 2 so far\n",
            "5. e - 3 so far\n",
            "6. n - 3 so far\n",
            "7. t - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"o\" are there in the word \"veto\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of o's in the word \"veto\"\n",
            "1. v - 0 so far\n",
            "2. e - 1 so far\n",
            "3. t - 1 so far\n",
            "4. o - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"y\" are there in the word \"ivory\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of y's in the word ivory\n",
            "1. i - 0 so far\n",
            "2. y - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"torrent\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of n's in the word \"torrent\"\n",
            "1. t - [count of requested letter so far] = 1 so far\n",
            "2. o - [count of requested letter so far] = 1 so far\n",
            "3. r - [count of requested letter so far] = 1 so far\n",
            "4. o - [count of requested letter so far] = 2 so far\n",
            "5. t - [count of requested letter so far] = 2 so far\n",
            "6. o - [count of requested letter so far] = 3 so far\n",
            "7. r - [count of requested letter so far] = 3 so far\n",
            "8. n - [count of requested letter so far] = 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"whistle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. w - 0 so far\n",
            "2. h - 0 so far\n",
            "3. i - 0 so far\n",
            "4. s - 0 so far\n",
            "5. t - 0 so far\n",
            "6. e - 0 so far\n",
            "7. l - 0 so far\n",
            "8. l - 0 so far\n",
            "9. l - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"resolve\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. l - 0 so far\n",
            "2. o - 0 so far\n",
            "3. v - 0 so far\n",
            "4. e - 0 so far\n",
            "5. s - 0 so far\n",
            "6. i - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"mirage\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of i's in the word \"mirage\"\n",
            "1. m - 0 so far\n",
            "2. i - 1 so far\n",
            "3. r - 0 so far\n",
            "4. a - 1 so far\n",
            "5. g - 0 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"lunar\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word lunar\n",
            "1. l - 0 so far\n",
            "2. u - 0 so far\n",
            "3. a - 0 so far\n",
            "4. v - 0 so far\n",
            "5. a - 1 so far\n",
            "6. n - 1 so far\n",
            "So, the letter \"r\" appears 0 times in the word \"lunar\".\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. s - 0 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "4. a - 2 so far\n",
            "5. p - 3 so far\n",
            "6. \\SPAFAHPR\\ - 3 so far\n",
            "7. A - 4 so far\n",
            "8. F - 4 so far\n",
            "9. i - 5 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "5\n",
            "</answer>\n",
            "Extracted: 5\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of t's in the word mantle\n",
            "1. m - 1 so far\n",
            "2. a - 1 so far\n",
            "3. n - 1 so far\n",
            "4. t - 1 so far\n",
            "5. l - 1 so far\n",
            "6. e - 0 so far (no letter e after t)\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"sapphire\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. p - 1 so far\n",
            "2. a - 1 so far\n",
            "3. p - 2 so far\n",
            "4. a - 3 so far\n",
            "5. p - 4 so far\n",
            "6. a - 4 so far\n",
            "7. p - 5 so far\n",
            "8. h - 5 so far\n",
            "9. p - 6 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "6\n",
            "</answer>\n",
            "Extracted: 6\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"ivory\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word ivory\n",
            "1. i - 0 so far\n",
            "2. r - 1 so far\n",
            "3. v - 0 so far\n",
            "4. i - 1 so far\n",
            "5. o - 0 so far\n",
            "6. w - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"triumph\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. i - 1 so far\n",
            "2. i - 1 so far\n",
            "3. i - 1 so far\n",
            "4. i - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"zealous\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. z - 0 so far\n",
            "2. e - 1 so far\n",
            "3. a - 2 so far\n",
            "4. z - 3 so far\n",
            "5. l - 4 so far\n",
            "6. a - 5 so far\n",
            "7. s - 5 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "5\n",
            "</answer>\n",
            "Extracted: 5\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"verge\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. v - 0 so far\n",
            "2. e - 1 so far\n",
            "3. r - 1 so far\n",
            "4. g - 0 so far\n",
            "5. e - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"onset\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. o - 1 so far\n",
            "2. n - 1 so far\n",
            "3. s - 1 so far\n",
            "4. e - 1 so far\n",
            "5. t - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"crisp\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. c - 1 so far\n",
            "2. r - 0 so far (no following r's)\n",
            "3. i - 0 so far (no following i's)\n",
            "4. s - 0 so far (no following s's)\n",
            "5. p - 0 so far (no following p's)\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"d\" are there in the word \"lantern\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. l - 0 so far\n",
            "2. a - 1 so far\n",
            "3. n - 0 so far\n",
            "4. t - 0 so far\n",
            "5. e - 1 so far\n",
            "6. r - 0 so far\n",
            "7. m - 1 so far\n",
            "So far, there are no \"d\"s in the word \"lantern\".\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"fusion\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of \"c\"s in the word \"fusion\"\n",
            "1. f - 0 so far\n",
            "2. u - 0 so far\n",
            "3. s - 0 so far\n",
            "4. i - 0 so far\n",
            "5. o - 0 so far\n",
            "6. n - 0 so far\n",
            "7. c - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"o\" are there in the word \"onset\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. o - 1 so far\n",
            "2. n - 1 so far\n",
            "3. s - 0 so far\n",
            "4. e - 0 so far\n",
            "5. t - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"q\" are there in the word \"wisp\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of q's in the word wisp\n",
            "1. w - 0 so far\n",
            "2. i - 1 so far\n",
            "3. s - 2 so far\n",
            "4. p - 3 so far\n",
            "5. - 4 so far\n",
            "6. s - 5 so far (but it's the last letter, so we stop here)\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"radius\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of a's in the word radius\n",
            "1. r - 0 so far\n",
            "2. a - 1 so far\n",
            "3. a - 1 (total count so far is 1)\n",
            "4. s - 1 so far\n",
            "5. i - 1 so far\n",
            "6. d - 1 so far\n",
            "7. a - 1 (total count so far is 1)\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"v\" are there in the word \"elude\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of v's in the word \"elude\"\n",
            "1. e - 1 so far\n",
            "2. l - 1 so far\n",
            "3. u - 1 so far\n",
            "4. d - 1 so far\n",
            "5. e - 2 so far (last occurrence of v)\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"enchant\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. e - 0 so far\n",
            "2. n - 1 so far\n",
            "3. c - 0 so far\n",
            "4. h - 0 so far\n",
            "5. a - 1 so far\n",
            "6. n - 2 so far\n",
            "7. t - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"orchard\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of h's in the word orchard\n",
            "1. o - 0 so far\n",
            "2. h - 1 so far\n",
            "3. r - 1 so far\n",
            "4. a - 2 so far\n",
            "5. c - 2 so far\n",
            "6. d - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"maze\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. m - 1 so far\n",
            "2. a - 1, 1 so far\n",
            "3. z - 0, 1 so far\n",
            "4. e - 0, 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. m - 0 so far\n",
            "2. a - 1 so far\n",
            "3. n - 1 so far\n",
            "4. t - 2 so far\n",
            "5. l - 3 so far\n",
            "6. e - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"d\" are there in the word \"gossipy\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of d's in the word gossipy\n",
            "1. g - 0 so far\n",
            "2. o - 0 so far\n",
            "3. s - 0 so far\n",
            "4. s - 1 so far\n",
            "5. o - 1 so far\n",
            "6. g - 1 so far\n",
            "7. i - 2 so far\n",
            "8. p - 3 so far\n",
            "9. y - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"f\" are there in the word \"ivory\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of f's in the word ivory\n",
            "1. i - 1 so far\n",
            "2. v - 1 so far\n",
            "3. r - 1 so far\n",
            "4. w - 1 so far\n",
            "5. 1 - 1 so far\n",
            "6. e - 1 so far\n",
            "7. o - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"capture\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. c - 0 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "4. r - 1 so far\n",
            "5. c - 1 so far\n",
            "6. a - 2 so far\n",
            "7. t - 2 so far\n",
            "8. e - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"prelude\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. p - 0 so far\n",
            "2. r - 0 so far\n",
            "3. e - 1 so far\n",
            "4. u - 1 so far\n",
            "5. l - 2 so far\n",
            "6. e - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"crisp\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. c - 1 so far\n",
            "2. r - 1 so far\n",
            "3. r - 1 (already counted) so far\n",
            "4. s - 1 so far\n",
            "5. p - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"enchant\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of t's in the word enchant\n",
            "1. e - 0 so far\n",
            "2. n - 1 so far\n",
            "3. c - 1 so far\n",
            "4. h - 2 so far\n",
            "5. a - 3 so far\n",
            "6. n - 4 so far\n",
            "7. t - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"scarab\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. s - 1 so far\n",
            "2. c - 0 so far\n",
            "3. a - 1 so far\n",
            "4. r - 1 so far\n",
            "5. b - 0 so far\n",
            "6. c - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"oath\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. o - 0 so far\n",
            "2. a - 1 so far\n",
            "3. h - 0 so far\n",
            "Therefore, the number of times the letter \"a\" appears in the word \"oath\" is 1.\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"b\" are there in the word \"prelude\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. p - 1 so far\n",
            "2. r - 1 so far\n",
            "3. e - 1 so far\n",
            "4. l - 1 so far\n",
            "5. u - 1 so far\n",
            "6. d - 1 so far\n",
            "7. e - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. m - 1 so far\n",
            "2. a - 1 so far\n",
            "3. n - 1 so far\n",
            "4. t - 2 so far\n",
            "5. l - 1 so far\n",
            "So far, there are 3 'm's in the word \"mantle\".\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"grim\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. g - 0 so far\n",
            "2. r - 1 so far\n",
            "3. i - 1 so far\n",
            "4. m - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"oath\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of h's in the word \"oath\"\n",
            "1. o - 0 so far\n",
            "2. a - 1 so far\n",
            "3. h - 1 so far\n",
            "4. h - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"aperture\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. a - 0 so far\n",
            "2. p - 1 so far\n",
            "3. a - 1 so far\n",
            "4. u - 2 so far\n",
            "5. p - 2 so far\n",
            "6. e - 2 so far\n",
            "7. r - 3 so far\n",
            "8. t - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"rust\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of s's in the word \"rust\"\n",
            "1. r - 0 so far\n",
            "2. u - 0 so far\n",
            "3. s - 1 so far\n",
            "4. t - 1 so far\n",
            "5. s - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "time: 35min 17s (started: 2025-12-22 19:32:16 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Now let's train for real! Let's do a longer training that will take an hour or more\n",
        "# Note: If this run is successful, you can consider doing a longer train\n",
        "# to see what happens, but that's beyond the scope of this project.\n",
        "\n",
        "# Full training\n",
        "training_args = GRPOConfig(\n",
        "    **grpo_params,  # Use grpo_params, NOT COMMON_GRPO_TRAINING_PARAMS\n",
        "    max_steps = 75,\n",
        ")\n",
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    processing_class=tokenizer,\n",
        "    reward_funcs=REWARD_FUNCS,\n",
        "    args=training_args,\n",
        "    train_dataset=ds,\n",
        ")\n",
        "trainer_res = trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olfOkiLJHfBa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "579830dc-ecb6-4dab-9912-e8c40692ec45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "available columns: dict_keys(['loss', 'grad_norm', 'learning_rate', 'num_tokens', 'completions/mean_length', 'completions/min_length', 'completions/max_length', 'completions/clipped_ratio', 'completions/mean_terminated_length', 'completions/min_terminated_length', 'completions/max_terminated_length', 'rewards/numbering_reward_func/mean', 'rewards/numbering_reward_func/std', 'rewards/spelling_reward_func/mean', 'rewards/spelling_reward_func/std', 'rewards/counting_reward_func/mean', 'rewards/counting_reward_func/std', 'rewards/format_reward_func/mean', 'rewards/format_reward_func/std', 'rewards/correct_answer_reward_func/mean', 'rewards/correct_answer_reward_func/std', 'reward', 'reward_std', 'frac_reward_zero_std', 'completion_length', 'kl', 'epoch', 'step'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 159 ms (started: 2025-12-22 20:07:43 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Show the total (sum) of the rewards as well as the correct_answer_reward_func (means with in the batch)\n",
        "# Do you see the rewards increasing? Does the model get the correct answer\n",
        "# more frequently toward the end?\n",
        "# No changes needed in this cell\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# If you want to graph other columns, check these out\n",
        "print(f\"available columns: {trainer.state.log_history[0].keys()}\")\n",
        "\n",
        "log_df = pd.DataFrame(trainer.state.log_history)\n",
        "log_df[\"reward\"].plot()\n",
        "log_df[\"rewards/correct_answer_reward_func/mean\"].plot()\n",
        "\n",
        "# Show the legend\n",
        "plt.legend([\"reward\", \"rewards/correct_answer_reward_func/mean\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COGF7PR6HfBb"
      },
      "source": [
        "## View the results\n",
        "Now let's try the model we just trained!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMGM5_DbHfBb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43ee362c-aaa2-44a9-96f7-aa22186423aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('grpo_saved_lora/tokenizer_config.json',\n",
              " 'grpo_saved_lora/special_tokens_map.json',\n",
              " 'grpo_saved_lora/chat_template.jinja',\n",
              " 'grpo_saved_lora/vocab.json',\n",
              " 'grpo_saved_lora/merges.txt',\n",
              " 'grpo_saved_lora/added_tokens.json',\n",
              " 'grpo_saved_lora/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 41.3 s (started: 2025-12-22 20:09:29 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Save the LoRA adapters\n",
        "# No changes needed in this cell\n",
        "\n",
        "# Save the LoRA model\n",
        "# model.save_lora(\"grpo_saved_lora\")\n",
        "model.save_pretrained(\"grpo_saved_lora\")\n",
        "tokenizer.save_pretrained(\"grpo_saved_lora\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vtv8MdnwHfBc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65d67506-34e0-4f4c-8570-62a11d58f0d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.93 ms (started: 2025-12-22 20:14:50 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Create a function to run both the original model and the updated model\n",
        "# No changes needed in this cell\n",
        "\n",
        "def compare_old_and_new_model(messages):\n",
        "    # 1. Text vorbereiten\n",
        "    text = tokenizer.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "    inputs = tokenizer([text], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "\n",
        "    # ---  1: using new model - is current active\n",
        "    output_new = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=1024,\n",
        "        temperature=0.8,\n",
        "        top_p=0.95,\n",
        "        use_cache=True,\n",
        "    )\n",
        "    new_text = tokenizer.decode(output_new[0], skip_special_tokens=True).split(\"assistant\")[-1].strip()\n",
        "\n",
        "    # ---  2: using old model\n",
        "    with model.disable_adapter():\n",
        "        output_old = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=1024,\n",
        "            temperature=0.8,\n",
        "            top_p=0.95,\n",
        "            use_cache=True,\n",
        "        )\n",
        "    old_text = tokenizer.decode(output_old[0], skip_special_tokens=True).split(\"assistant\")[-1].strip()\n",
        "\n",
        "    print(\"=== OLD (Base Model) ===\")\n",
        "    print(old_text)\n",
        "    print(\"\\n\\n=== NEW (GRPO LoRA) ===\")\n",
        "    print(new_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LhCz3I5HfBc"
      },
      "source": [
        "### Compare the old and new models on the letter-counting task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0R4S2EoHfBc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f55b5c41-4804-48d7-de45-2d24a01db6e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== OLD (Base Model) ===\n",
            "<reasoning>\n",
            "Counting the number of a's in the word idea\n",
            "1. i - 0 so far\n",
            "2. d - 1 so far\n",
            "3. e - 2 so far\n",
            "4. a - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "\n",
            "\n",
            "=== NEW (GRPO LoRA) ===\n",
            "<reasoning>\n",
            "1. i - 1 so far\n",
            "2. d - 1 so far\n",
            "3. e - 1 so far\n",
            "4. a - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "time: 8.09 s (started: 2025-12-22 20:14:56 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Let's try spelling the first word from the dataset\n",
        "\n",
        "# Load the first item from the dataset (index 0) and compare the old and new models\n",
        "compare_old_and_new_model(ds[0][\"prompt\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6UEVA8fHfBc"
      },
      "source": [
        "Our model is better at spelling and counter letters in words! Depending on your reward functions, the size of your model, and the amount of steps trained, results may vary.\n",
        "\n",
        "For about an hour of training time, your model may not be perfect (or maybe it is), but it's definitely moving in the right direction!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltP7rIERHfBc"
      },
      "source": [
        "### Make sure the model did not forget basic facts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKOSJaFBHfBc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83bde9d2-b714-4936-d83a-c0c57b23d8b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== OLD (Base Model) ===\n",
            "The capital of France is Paris.\n",
            "\n",
            "\n",
            "=== NEW (GRPO LoRA) ===\n",
            "The capital of France is Paris.\n",
            "time: 1.26 s (started: 2025-12-22 20:15:26 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Let's see if the model still remembers some of the facts from its original training\n",
        "\n",
        "# Ask both the old and new models a question the model is likely to know,\n",
        "# e.g. a well-known capital city\n",
        "compare_old_and_new_model([\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qx43__FSHfBd"
      },
      "source": [
        "Great job! Congrats on completing the project! 🎉🤗"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d6a2ea0a4fe4f11beaa92fc59517763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a241eb57c5a9490eb8fb77e2912b3546",
              "IPY_MODEL_58afcc301e294a21a758b82b8ab711ce",
              "IPY_MODEL_d7f01ca218cb4a06bc2c012cd484ec2a"
            ],
            "layout": "IPY_MODEL_4a257fce2aa544fb839e1c49aaf7c1c6"
          }
        },
        "a241eb57c5a9490eb8fb77e2912b3546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b880135e3b6342249c428a00526c3536",
            "placeholder": "​",
            "style": "IPY_MODEL_ae1a3fbf406f4e589fd62cf59b8376ac",
            "value": "model.safetensors: 100%"
          }
        },
        "58afcc301e294a21a758b82b8ab711ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b1b723f38184b849ef51ea31cf4680a",
            "max": 2355738764,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3cd87d2a6c0410a99783bcc5141e9ed",
            "value": 2355738764
          }
        },
        "d7f01ca218cb4a06bc2c012cd484ec2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50d1ee387c1845b19491b17391b60bd8",
            "placeholder": "​",
            "style": "IPY_MODEL_ae11e89d588642429f7ababde6b55481",
            "value": " 2.36G/2.36G [00:28&lt;00:00, 81.5MB/s]"
          }
        },
        "4a257fce2aa544fb839e1c49aaf7c1c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b880135e3b6342249c428a00526c3536": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae1a3fbf406f4e589fd62cf59b8376ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b1b723f38184b849ef51ea31cf4680a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3cd87d2a6c0410a99783bcc5141e9ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50d1ee387c1845b19491b17391b60bd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae11e89d588642429f7ababde6b55481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d421ad0da914ca4876dfce2b630dda7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58e7a6a503bf475688eddfb220f36dd9",
              "IPY_MODEL_2acac5dbbb994ce896c5225731db4312",
              "IPY_MODEL_446274b77b9c43ab8e12d87be83d7c94"
            ],
            "layout": "IPY_MODEL_f586a3d36b6a46e3a9b2dd3abcdb3115"
          }
        },
        "58e7a6a503bf475688eddfb220f36dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c517e6a097d24946a04030b823aa7b22",
            "placeholder": "​",
            "style": "IPY_MODEL_04d82b29d8064ad8acb63690f4e7d8c9",
            "value": "tokenizer_config.json: "
          }
        },
        "2acac5dbbb994ce896c5225731db4312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17fa574a6fff493fadb0d59fda8b6ec8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_116785b6cf9e4b1b8f31903e26f91a5e",
            "value": 1
          }
        },
        "446274b77b9c43ab8e12d87be83d7c94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3283396db6f04e8ca947d17d812c0258",
            "placeholder": "​",
            "style": "IPY_MODEL_5d51d2bde0044acb803bd900848a067b",
            "value": " 7.36k/? [00:00&lt;00:00, 231kB/s]"
          }
        },
        "f586a3d36b6a46e3a9b2dd3abcdb3115": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c517e6a097d24946a04030b823aa7b22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d82b29d8064ad8acb63690f4e7d8c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17fa574a6fff493fadb0d59fda8b6ec8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "116785b6cf9e4b1b8f31903e26f91a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3283396db6f04e8ca947d17d812c0258": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d51d2bde0044acb803bd900848a067b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b15f2cf9e39445cb7278c7a36de2fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d236f2182ea445baadf712aeeeefd0ff",
              "IPY_MODEL_8b6e7ef252f04a44995a92364bee6c98",
              "IPY_MODEL_662e56eb250c4504bf5f9e6a3b76644f"
            ],
            "layout": "IPY_MODEL_597ccff8a42547fa997578a637d44870"
          }
        },
        "d236f2182ea445baadf712aeeeefd0ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5363d3dcafd64661be1897615078a9d5",
            "placeholder": "​",
            "style": "IPY_MODEL_06d3db43480f43fe9d96fc705783c37f",
            "value": "vocab.json: "
          }
        },
        "8b6e7ef252f04a44995a92364bee6c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3476755500c4502bb4a7645887beb61",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7211648a3764f11835c8572ed7fb183",
            "value": 1
          }
        },
        "662e56eb250c4504bf5f9e6a3b76644f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_928fc12e232b41d39789894bcda30638",
            "placeholder": "​",
            "style": "IPY_MODEL_3f74dd311a194a6e9fd68f4bdb4e0411",
            "value": " 2.78M/? [00:00&lt;00:00, 29.6MB/s]"
          }
        },
        "597ccff8a42547fa997578a637d44870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5363d3dcafd64661be1897615078a9d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06d3db43480f43fe9d96fc705783c37f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3476755500c4502bb4a7645887beb61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f7211648a3764f11835c8572ed7fb183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "928fc12e232b41d39789894bcda30638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f74dd311a194a6e9fd68f4bdb4e0411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1205492a99c4d99980844793c76750c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_158c419b4980404f8d7fe2f56a1a6466",
              "IPY_MODEL_f1c2ccb785a142bb8367733ce687a967",
              "IPY_MODEL_cd168c57025340299e9e175164f844e7"
            ],
            "layout": "IPY_MODEL_caf7f31f0e864a289bcbf2b2edc70524"
          }
        },
        "158c419b4980404f8d7fe2f56a1a6466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a83cec22ffa9452e82a13196418bd08d",
            "placeholder": "​",
            "style": "IPY_MODEL_593d47aedcec4a59925d97ac279713db",
            "value": "merges.txt: "
          }
        },
        "f1c2ccb785a142bb8367733ce687a967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e65e71889d14e47a83a969c3cb79632",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a5b5b469b9b4dee8f07d9d348c7204e",
            "value": 1
          }
        },
        "cd168c57025340299e9e175164f844e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0023acb766f478b8ddb70b7c2692143",
            "placeholder": "​",
            "style": "IPY_MODEL_13302c1cea63450184f2ae7d43fb68f1",
            "value": " 1.67M/? [00:00&lt;00:00, 32.3MB/s]"
          }
        },
        "caf7f31f0e864a289bcbf2b2edc70524": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a83cec22ffa9452e82a13196418bd08d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "593d47aedcec4a59925d97ac279713db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e65e71889d14e47a83a969c3cb79632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9a5b5b469b9b4dee8f07d9d348c7204e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0023acb766f478b8ddb70b7c2692143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13302c1cea63450184f2ae7d43fb68f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65ae6380def843bfbc5502ba29875416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f273eb103c564193b84933dc7293187c",
              "IPY_MODEL_5fe79d1e81ab4d5c9a4f8d35d27243de",
              "IPY_MODEL_b17ccf312e4b494e9144ad4eaf7eab42"
            ],
            "layout": "IPY_MODEL_dc07558c40e94328b891d30c4ebcac8c"
          }
        },
        "f273eb103c564193b84933dc7293187c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30be81ea34fb43b3a82f161a7e030680",
            "placeholder": "​",
            "style": "IPY_MODEL_f56390f301c340fdb6c3224b0ed91927",
            "value": "added_tokens.json: 100%"
          }
        },
        "5fe79d1e81ab4d5c9a4f8d35d27243de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eca1e8e5e0d4ce6bff9e87367381b21",
            "max": 605,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b31a1b8b7f747eca7e8bdad0f1dc966",
            "value": 605
          }
        },
        "b17ccf312e4b494e9144ad4eaf7eab42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3573c80bc33e458fa603b9ccc90beecb",
            "placeholder": "​",
            "style": "IPY_MODEL_f7c131024ecf44b08277488f338eab0f",
            "value": " 605/605 [00:00&lt;00:00, 23.0kB/s]"
          }
        },
        "dc07558c40e94328b891d30c4ebcac8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30be81ea34fb43b3a82f161a7e030680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f56390f301c340fdb6c3224b0ed91927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2eca1e8e5e0d4ce6bff9e87367381b21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b31a1b8b7f747eca7e8bdad0f1dc966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3573c80bc33e458fa603b9ccc90beecb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7c131024ecf44b08277488f338eab0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65c48e3422064478a198eaba17a17475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8874128e0474fd3a4b4b44b40b3d6df",
              "IPY_MODEL_9a4e52149a95448e8cefb42ab83672a2",
              "IPY_MODEL_403bea2c9bcf4e7dba35b2bd8876e1ff"
            ],
            "layout": "IPY_MODEL_51e64cf1403b4045999a447e8d40caaf"
          }
        },
        "f8874128e0474fd3a4b4b44b40b3d6df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8be6a599f4f9402ca8ec35cdd4c8d07c",
            "placeholder": "​",
            "style": "IPY_MODEL_4750ca14fd8b44a4bddd731f26a134ce",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "9a4e52149a95448e8cefb42ab83672a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8cec81bdcc14a65817b136fbfc646b9",
            "max": 614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a665d260c6c486f826d207bf225b126",
            "value": 614
          }
        },
        "403bea2c9bcf4e7dba35b2bd8876e1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_911791bbc14d4b94b1ea6f5716b8d3b0",
            "placeholder": "​",
            "style": "IPY_MODEL_d964790e73e94a23b9c5460859c4c5ed",
            "value": " 614/614 [00:00&lt;00:00, 25.3kB/s]"
          }
        },
        "51e64cf1403b4045999a447e8d40caaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8be6a599f4f9402ca8ec35cdd4c8d07c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4750ca14fd8b44a4bddd731f26a134ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8cec81bdcc14a65817b136fbfc646b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a665d260c6c486f826d207bf225b126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "911791bbc14d4b94b1ea6f5716b8d3b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d964790e73e94a23b9c5460859c4c5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ce3910074fb4acca5fc387ada827bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe80d7c0cec642589ecaf2305fa7596f",
              "IPY_MODEL_695b480254cd4667ad655f8c693c352b",
              "IPY_MODEL_a1ae42af868248b788e4b77d97eac30a"
            ],
            "layout": "IPY_MODEL_bde27c81074e4713823ff47cf92dbfb0"
          }
        },
        "fe80d7c0cec642589ecaf2305fa7596f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_876eee7276f044faa22f2240bdbbc2d7",
            "placeholder": "​",
            "style": "IPY_MODEL_96ce796505e94c43a37cce9de7be5c5a",
            "value": "tokenizer.json: 100%"
          }
        },
        "695b480254cd4667ad655f8c693c352b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe37bc0a19f24c0099874b16493f5308",
            "max": 11421896,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_510cc381934649ca8b21bcfe3e27805d",
            "value": 11421896
          }
        },
        "a1ae42af868248b788e4b77d97eac30a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbc2616b6c02499fb45540f4eaf8aa50",
            "placeholder": "​",
            "style": "IPY_MODEL_5b650d688c574f67b43f9879766be302",
            "value": " 11.4M/11.4M [00:01&lt;00:00, 12.1MB/s]"
          }
        },
        "bde27c81074e4713823ff47cf92dbfb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "876eee7276f044faa22f2240bdbbc2d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96ce796505e94c43a37cce9de7be5c5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe37bc0a19f24c0099874b16493f5308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "510cc381934649ca8b21bcfe3e27805d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbc2616b6c02499fb45540f4eaf8aa50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b650d688c574f67b43f9879766be302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adefb166bc4e4afbb36c2797087d0d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_163893b19286416782630eb7b28659e4",
              "IPY_MODEL_512bdb3486a442d5a5021788e4adeca4",
              "IPY_MODEL_cddf003ae2e545c0b705d7413b5589c1"
            ],
            "layout": "IPY_MODEL_5a0c73753e894c02ab949ab23355baca"
          }
        },
        "163893b19286416782630eb7b28659e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cccce94d8cd948c28442a8ac4ea87d93",
            "placeholder": "​",
            "style": "IPY_MODEL_cf9b7eb6474043108366ad4ce683d181",
            "value": "Generating train split: "
          }
        },
        "512bdb3486a442d5a5021788e4adeca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c4552bca0014b97b82b68670c46b5ab",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de0b1cd793aa4029a578664c248d5a63",
            "value": 1
          }
        },
        "cddf003ae2e545c0b705d7413b5589c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf58e70db2de4ff08ae90102721e4ce7",
            "placeholder": "​",
            "style": "IPY_MODEL_17a620c6ac1a4693927696b399b586d0",
            "value": " 401/0 [00:00&lt;00:00, 7483.03 examples/s]"
          }
        },
        "5a0c73753e894c02ab949ab23355baca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cccce94d8cd948c28442a8ac4ea87d93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf9b7eb6474043108366ad4ce683d181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c4552bca0014b97b82b68670c46b5ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "de0b1cd793aa4029a578664c248d5a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf58e70db2de4ff08ae90102721e4ce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17a620c6ac1a4693927696b399b586d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78ea5175bae64de8b74bb11c12d5dd92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5a24686257949b497fb37b44f2c41fa",
              "IPY_MODEL_1fc840809a2b4dc2ba78e6489fe19a02",
              "IPY_MODEL_7936147c93f64490ac9ff784a2e4b140"
            ],
            "layout": "IPY_MODEL_be867cdf6f5d4fe69d7de7e5559a9e36"
          }
        },
        "a5a24686257949b497fb37b44f2c41fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb9dbfb84b44484ca0da2b7804ca7c72",
            "placeholder": "​",
            "style": "IPY_MODEL_ed28f1a051a9482c93cf720f51f21aed",
            "value": "Map: 100%"
          }
        },
        "1fc840809a2b4dc2ba78e6489fe19a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b778a119f474f43944a150940a1fa11",
            "max": 401,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8b386a9e4154b288ce1b477d1c754e6",
            "value": 401
          }
        },
        "7936147c93f64490ac9ff784a2e4b140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41d97dd90e2849c39c632c0385a494a9",
            "placeholder": "​",
            "style": "IPY_MODEL_a573f22e7c094ed88a41f9d46b274e0d",
            "value": " 401/401 [00:00&lt;00:00, 6967.11 examples/s]"
          }
        },
        "be867cdf6f5d4fe69d7de7e5559a9e36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb9dbfb84b44484ca0da2b7804ca7c72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed28f1a051a9482c93cf720f51f21aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b778a119f474f43944a150940a1fa11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8b386a9e4154b288ce1b477d1c754e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41d97dd90e2849c39c632c0385a494a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a573f22e7c094ed88a41f9d46b274e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}